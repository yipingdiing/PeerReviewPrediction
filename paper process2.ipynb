{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3102386c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total records: 5886\n",
      "✅ Saved 5886 paper_ids to E:\\judita's project\\new data 2\\paper_ids.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ===== 1) Specify the file path directly =====\n",
    "# Change this to your actual file name\n",
    "file_name = r\"E:\\judita's project\\全部数据\\judita_统一ICLR7.7更新后.json\"\n",
    "\n",
    "# ===== 2) Read JSON data =====\n",
    "with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# ===== 3) If the top level is a dict, extract the list from it; otherwise, it is a list directly =====\n",
    "if isinstance(data, dict):\n",
    "    for v in data.values():\n",
    "        if isinstance(v, list):\n",
    "            records = v\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(\"List not found in the JSON file, please check the structure\")\n",
    "else:\n",
    "    records = data\n",
    "\n",
    "print(\"✅ Total records:\", len(records))\n",
    "\n",
    "# ===== 4) Extract paper_id =====\n",
    "paper_ids = [rec.get(\"id\", None) for rec in records]\n",
    "\n",
    "# ===== 5) Save as CSV =====\n",
    "df = pd.DataFrame({\"paper_id\": paper_ids})\n",
    "output_file = r\"E:\\judita's project\\new data 2\\paper_ids.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Saved {len(df)} paper_ids to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3947317c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Iteration and counting complete\n",
      "Total number of paper_ids: 5886\n",
      "Number of matched IDs: 5817\n",
      "Number of unmatched IDs: 69\n",
      "Saved: E:\\judita's project\\new data 2\\paper_id_section_counts.csv\n",
      "Unmatched IDs saved: E:\\judita's project\\new data 2\\unmatched_paper_ids.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ===== 1) Specify file paths =====\n",
    "# Should contain one column of paper_ids (column name is flexible, will be auto-detected)\n",
    "paper_ids_file = r\"E:\\judita's project\\new data 2\\paper_ids.csv\"\n",
    "# The dataset (CSV, must contain a 'paper_id' column)\n",
    "records_file = r\"E:\\judita's project\\new data\\matched_sections_cleaned_final.csv\"\n",
    "\n",
    "# ===== 2) Read paper_ids (preserving original order) =====\n",
    "df_ids_raw = pd.read_csv(paper_ids_file)\n",
    "\n",
    "# Fault tolerance: Identify the paper_id column name (allows for names other than exactly 'paper_id')\n",
    "id_col = None\n",
    "for c in df_ids_raw.columns:\n",
    "    if c.strip().lower() == \"paper_id\":\n",
    "        id_col = c\n",
    "        break\n",
    "# If not found, default to the first column\n",
    "if id_col is None:\n",
    "    id_col = df_ids_raw.columns[0]\n",
    "\n",
    "paper_ids = df_ids_raw[id_col].astype(str).fillna(\"\").tolist()\n",
    "\n",
    "# ===== 3) Read the records CSV (with error handling) =====\n",
    "df_rec = pd.read_csv(\n",
    "    records_file,\n",
    "    on_bad_lines=\"skip\",  # Skip bad lines\n",
    "    engine=\"python\",      # More robust error handling\n",
    ")\n",
    "\n",
    "# Ensure the 'paper_id' column exists\n",
    "if \"paper_id\" not in df_rec.columns:\n",
    "    raise ValueError(\"The 'paper_id' column was not found in the records dataset. Please check the file.\")\n",
    "\n",
    "# Unify types and clean (strip whitespace)\n",
    "df_rec[\"paper_id\"] = df_rec[\"paper_id\"].astype(str).str.strip()\n",
    "paper_ids_norm = [str(x).strip() for x in paper_ids]\n",
    "\n",
    "# ===== 4) Pre-calculate the occurrence count for each paper_id (using a hash map, O(n) for counting) =====\n",
    "counts = df_rec[\"paper_id\"].value_counts(dropna=False).to_dict()\n",
    "\n",
    "# ===== 5) Tally counts one by one, following the order in paper_ids.csv =====\n",
    "section_count_list = [int(counts.get(pid, 0)) for pid in paper_ids_norm]\n",
    "\n",
    "# ===== 6) Assemble the results (preserving original order) =====\n",
    "result = pd.DataFrame({\n",
    "    \"paper_id\": paper_ids,          # Original values (as they appear in your file)\n",
    "    \"section_count\": section_count_list,\n",
    "    \"matched\": [c > 0 for c in section_count_list]\n",
    "})\n",
    "\n",
    "# ===== 7) Tally and print the output =====\n",
    "total_ids = len(result)\n",
    "unmatched_ids = (result[\"section_count\"] == 0).sum()\n",
    "matched_ids = total_ids - unmatched_ids\n",
    "\n",
    "print(\"✅ Iteration and counting complete\")\n",
    "print(\"Total number of paper_ids:\", total_ids)\n",
    "print(\"Number of matched IDs:\", matched_ids)\n",
    "print(\"Number of unmatched IDs:\", unmatched_ids)\n",
    "\n",
    "# ===== 8) Save the results =====\n",
    "out_all = r\"E:\\judita's project\\new data 2\\paper_id_section_counts.csv\"\n",
    "out_unmatched = r\"E:\\judita's project\\new data 2\\unmatched_paper_ids.csv\"\n",
    "result.to_csv(out_all, index=False)\n",
    "result.loc[result[\"section_count\"] == 0, [\"paper_id\"]].to_csv(out_unmatched, index=False)\n",
    "\n",
    "print(\"Saved:\", out_all)\n",
    "print(\"Unmatched IDs saved:\", out_unmatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35bb6d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Number of records with matched=True: 5817\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取原始文件\n",
    "df = pd.read_csv(r\"E:\\judita's project\\new data 2\\paper_id_section_counts.csv\")\n",
    "\n",
    "# 过滤 matched 为 True 的记录\n",
    "df_filtered = df[df[\"matched\"] == True].copy()\n",
    "\n",
    "# 打印记录数量\n",
    "print(f\"✅ Number of records with matched=True: {len(df_filtered)}\")\n",
    "\n",
    "# 删除 matched 列\n",
    "df_filtered.drop(columns=[\"matched\"], inplace=True)\n",
    "\n",
    "# 保存为新的 CSV 文件\n",
    "df_filtered.to_csv(\"paper_id_section_counts_only-true.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dde9ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processing complete\n",
      "Total number of paper_ids: 5817\n",
      "Number of matched paper_ids: 5817\n",
      "Number of unmatched paper_ids: 0\n",
      "Output file: E:\\judita's project\\new data 2\\paper_id_intro_conclusion.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ===== 1) Specify file paths =====\n",
    "# File containing the paper_id column\n",
    "ids_file = r\"E:\\judita's project\\new data 2\\paper_id_section_counts_only-true.csv\"\n",
    "# Each row is a section record, containing paper_id and section_content_vila\n",
    "records_file = r\"E:\\judita's project\\new data\\matched_sections_cleaned_final.csv\"\n",
    "\n",
    "# ===== 2) Read the paper_id column (preserving original order) =====\n",
    "df_ids_raw = pd.read_csv(ids_file)\n",
    "id_col = next((c for c in df_ids_raw.columns if c.strip().lower() == \"paper_id\"), df_ids_raw.columns[0])\n",
    "df_ids = df_ids_raw[[id_col]].rename(columns={id_col: \"paper_id\"})\n",
    "df_ids[\"paper_id\"] = df_ids[\"paper_id\"].astype(str).str.strip()\n",
    "\n",
    "# ===== 3) Read the records CSV (preserving original file order) =====\n",
    "df_rec = pd.read_csv(\n",
    "    records_file,\n",
    "    on_bad_lines=\"skip\",\n",
    "    engine=\"python\"\n",
    ")\n",
    "\n",
    "if \"paper_id\" not in df_rec.columns or \"section_content_vila\" not in df_rec.columns:\n",
    "    raise ValueError(\"The CSV must contain both 'paper_id' and 'section_content_vila' columns!\")\n",
    "\n",
    "# Ensure data types\n",
    "df_rec[\"paper_id\"] = df_rec[\"paper_id\"].astype(str).str.strip()\n",
    "df_rec[\"section_content_vila\"] = df_rec[\"section_content_vila\"].astype(str).fillna(\"\").str.strip()\n",
    "\n",
    "# ===== 4) Preserve original file order =====\n",
    "df_rec[\"_row\"] = np.arange(len(df_rec))  # Add a row number to each row\n",
    "df_rec_sorted = df_rec.sort_values(by=[\"paper_id\", \"_row\"], kind=\"mergesort\")\n",
    "\n",
    "# ===== 5) Get the intro/conclusion/count for each paper_id =====\n",
    "grp = df_rec_sorted.groupby(\"paper_id\")[\"section_content_vila\"]\n",
    "first_map = grp.first()   # First entry (based on file order)\n",
    "last_map  = grp.last()    # Last entry (based on file order)\n",
    "count_map = df_rec_sorted.groupby(\"paper_id\").size()\n",
    "\n",
    "# ===== 6) Assemble the results (preserving the original order from paper_ids.csv) =====\n",
    "result = df_ids.copy()\n",
    "result[\"section_count\"] = result[\"paper_id\"].map(count_map).fillna(0).astype(int)\n",
    "result[\"introduction\"]  = result[\"paper_id\"].map(first_map).fillna(\"\")\n",
    "result[\"conclusion\"]    = result[\"paper_id\"].map(last_map).fillna(\"\")\n",
    "\n",
    "# ===== 7) Save the output =====\n",
    "out_file = r\"E:\\judita's project\\new data 2\\paper_id_intro_conclusion.csv\"\n",
    "result.to_csv(out_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ Processing complete\")\n",
    "print(\"Total number of paper_ids:\", len(result))\n",
    "print(\"Number of matched paper_ids:\", (result['section_count'] > 0).sum())\n",
    "print(\"Number of unmatched paper_ids:\", (result['section_count'] == 0).sum())\n",
    "print(\"Output file:\", out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f0eda6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input files...\n",
      "Standardizing data from each file...\n",
      "Merging files and removing duplicates...\n",
      "Saving merged data to E:\\judita's project\\new data 2\\merged_papers_withlink.csv...\n",
      "\n",
      "--- Records with Missing Title or Abstract ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>rate0</th>\n",
       "      <th>rate1</th>\n",
       "      <th>rate2</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>decison</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>pdf_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id  rate0  rate1  rate2  avg_score  decison title abstract pdf_link\n",
       "3474        2      3      4      2        3.0        0   NaN      NaN      NaN\n",
       "3499        1      3      2      4        3.0        0   NaN      NaN      NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary ---\n",
      "✅ Processing complete.\n",
      "Total unique records saved: 6356\n",
      "Records missing a title: 2\n",
      "Records missing an abstract: 2\n",
      "Merged file saved to: E:\\judita's project\\new data 2\\merged_papers_withlink.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display # Import the display function for better notebook output\n",
    "\n",
    "# ---------- Inputs ----------\n",
    "# Define the paths for your input and output files.\n",
    "file1 = r\"E:\\judita's project\\2017sheet5.xlsx\"\n",
    "file2 = r\"E:\\judita's project\\2017sheet6.xlsx\"\n",
    "out_path = r\"E:\\judita's project\\new data 2\\merged_papers_withlink.csv\"\n",
    "\n",
    "# ---------- Helper Functions ----------\n",
    "\n",
    "def normalize_columns(df):\n",
    "    \"\"\"Creates a mapping from lowercase column names to original names.\"\"\"\n",
    "    return {c.lower(): c for c in df.columns}\n",
    "\n",
    "def pick_col(colmap, *candidates):\n",
    "    \"\"\"Finds the first matching column name from a list of candidates.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c is None:\n",
    "            continue\n",
    "        key = c.lower()\n",
    "        if key in colmap:\n",
    "            return colmap[key]\n",
    "    return None\n",
    "\n",
    "def extract_needed(df):\n",
    "    \"\"\"\n",
    "    Extracts and standardizes required columns from a DataFrame.\n",
    "    It flexibly finds columns like 'paper_id', 'rate0', 'title', etc.,\n",
    "    calculates the average score, and returns a clean DataFrame.\n",
    "    \"\"\"\n",
    "    colmap = normalize_columns(df)\n",
    "\n",
    "    # Find the actual column names using various possible candidates\n",
    "    c_paper_id = pick_col(colmap, \"paper_id\", \"id\", \"paperid\")\n",
    "    c_rate0    = pick_col(colmap, \"rate0\", \"rate_0\", \"r0\")\n",
    "    c_rate1    = pick_col(colmap, \"rate1\", \"rate_1\", \"r1\")\n",
    "    c_rate2    = pick_col(colmap, \"rate2\", \"rate_2\", \"r2\")\n",
    "    c_decison  = pick_col(colmap, \"decison\", \"decision\")\n",
    "    c_title    = pick_col(colmap, \"title\")\n",
    "    c_abstract = pick_col(colmap, \"abstract\", \"abs\")\n",
    "    c_pdf      = pick_col(colmap, \"pdf_link\", \"pdflink\", \"pdf\", \"pdf_url\", \"url\", \"link1\")\n",
    "\n",
    "    out = pd.DataFrame()\n",
    "    out[\"paper_id\"] = df[c_paper_id] if c_paper_id else np.nan\n",
    "\n",
    "    # Process ratings and calculate the average score\n",
    "    rates = []\n",
    "    for cname in [c_rate0, c_rate1, c_rate2]:\n",
    "        if cname:\n",
    "            # Convert to numeric, forcing errors to become NaN (Not a Number)\n",
    "            rates.append(pd.to_numeric(df[cname], errors=\"coerce\"))\n",
    "        else:\n",
    "            # If a rate column doesn't exist, create a series of NaNs\n",
    "            rates.append(pd.Series([np.nan] * len(df)))\n",
    "\n",
    "    rate_mat = np.vstack([r.values for r in rates]).T\n",
    "    out[\"avg_score\"] = np.nanmean(rate_mat, axis=1) # Calculate mean, ignoring NaNs\n",
    "\n",
    "    # Assign standardized columns to the output DataFrame\n",
    "    out[\"rate0\"] = rates[0]\n",
    "    out[\"rate1\"] = rates[1]\n",
    "    out[\"rate2\"] = rates[2]\n",
    "    out[\"decison\"]   = df[c_decison] if c_decison else np.nan\n",
    "    out[\"title\"]     = df[c_title] if c_title else np.nan\n",
    "    out[\"abstract\"]  = df[c_abstract] if c_abstract else np.nan\n",
    "    out[\"pdf_link\"]  = df[c_pdf] if c_pdf else np.nan\n",
    "\n",
    "    # Return the DataFrame with a fixed column order\n",
    "    final_cols = [\"paper_id\", \"rate0\", \"rate1\", \"rate2\", \"avg_score\", \"decison\", \"title\", \"abstract\", \"pdf_link\"]\n",
    "    return out[final_cols]\n",
    "\n",
    "# ---------- Main Logic ----------\n",
    "\n",
    "# 1. Read Excel files\n",
    "print(\"Reading input files...\")\n",
    "df1_raw = pd.read_excel(file1)\n",
    "df2_raw = pd.read_excel(file2)\n",
    "\n",
    "# 2. Process each file to standardize columns\n",
    "print(\"Standardizing data from each file...\")\n",
    "df1 = extract_needed(df1_raw)\n",
    "df2 = extract_needed(df2_raw)\n",
    "\n",
    "# 3. Combine, remove duplicates, and clean the data\n",
    "print(\"Merging files and removing duplicates...\")\n",
    "combined = pd.concat([df1, df2], ignore_index=True)\n",
    "combined_dedup = combined.drop_duplicates(subset=[\"paper_id\"], keep=\"first\").copy()\n",
    "# Replace empty strings or whitespace-only strings with NaN\n",
    "combined_dedup = combined_dedup.replace(r\"^\\s*$\", np.nan, regex=True)\n",
    "\n",
    "# 4. Identify rows that are missing a title or an abstract\n",
    "missing_title = combined_dedup[combined_dedup[\"title\"].isna()]\n",
    "missing_abstract = combined_dedup[combined_dedup[\"abstract\"].isna()]\n",
    "missing_records = pd.concat([missing_title, missing_abstract]).drop_duplicates()\n",
    "\n",
    "# 5. Save the final merged file\n",
    "print(f\"Saving merged data to {out_path}...\")\n",
    "combined_dedup.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 6. Display the records with missing data directly in the notebook\n",
    "print(\"\\n--- Records with Missing Title or Abstract ---\")\n",
    "if missing_records.empty:\n",
    "    print(\"No records are missing a title or abstract. Great!\")\n",
    "else:\n",
    "    # 'display()' renders the DataFrame as a formatted table in Jupyter\n",
    "    display(missing_records)\n",
    "\n",
    "# 7. Print a final summary\n",
    "print(\"\\n--- Summary ---\")\n",
    "print(f\"✅ Processing complete.\")\n",
    "print(f\"Total unique records saved: {len(combined_dedup)}\")\n",
    "print(f\"Records missing a title: {len(missing_title)}\")\n",
    "print(f\"Records missing an abstract: {len(missing_abstract)}\")\n",
    "print(f\"Merged file saved to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f545dc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] Successfully parsed: E:\\judita's project\\new data 2\\paper_id_intro_conclusion.csv (encoding=utf-8)\n",
      "[ok] Successfully parsed: E:\\judita's project\\new data 2\\merged_papers_withlink.csv (encoding=utf-8)\n",
      "✅ Merge complete\n",
      "Total rows in base table: 5817\n",
      "Rows with at least one matched field: 5817\n",
      "Rows with no matched fields: 0\n",
      "Unmatched items: None\n",
      "Output file: E:\\judita's project\\new data 2\\paper_id_intro_conclusion_enriched.csv\n",
      "✅ Column 'paper_id' has no null values\n",
      "✅ Column 'section_count' has no null values\n",
      "⚠️ Column 'introduction' has 5 null or empty values\n",
      "Examples of corresponding paper_ids: ['7R7fAoUygoa', 'D9I3drBz4UC', 'Fj1Tpym9KxH', 'FvfV64rovnY', 'RVhzamxHBjP']\n",
      "⚠️ Column 'conclusion' has 1 null or empty values\n",
      "Examples of corresponding paper_ids: ['VNJUTmR-CaZ']\n",
      "✅ Column 'rate0' has no null values\n",
      "✅ Column 'rate1' has no null values\n",
      "✅ Column 'rate2' has no null values\n",
      "✅ Column 'avg_score' has no null values\n",
      "✅ Column 'decision' has no null values\n",
      "✅ Column 'title' has no null values\n",
      "✅ Column 'abstract' has no null values\n",
      "✅ Column 'pdf_link' has no null values\n",
      "Full list of empty/null records has been exported to: E:\\judita's project\\new data 2\\missing_paper_ids_by_field.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io, csv\n",
    "import json\n",
    "\n",
    "# ========= Paths (modify as needed) =========\n",
    "base_file = r\"E:\\judita's project\\new data 2\\paper_id_intro_conclusion.csv\"\n",
    "# Contains paper_id + various metadata\n",
    "meta_file = r\"E:\\judita's project\\new data 2\\merged_papers_withlink.csv\"\n",
    "out_file  = r\"E:\\judita's project\\new data 2\\paper_id_intro_conclusion_enriched.csv\"\n",
    "unmatched_out = r\"E:\\judita's project\\new data 2\\unmatched_paper_id.csv\"\n",
    "\n",
    "# ========= Robust CSV Reader: Handles multiple encodings/delimiters, skips bad lines/quotes =========\n",
    "def sniff_sep(sample: str, default=','):\n",
    "    \"\"\"Detects the delimiter of a CSV sample.\"\"\"\n",
    "    try:\n",
    "        dialect = csv.Sniffer().sniff(sample, delimiters=[',',';','\\t','|'])\n",
    "        return dialect.delimiter\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def try_read_bytes(raw: bytes, enc: str):\n",
    "    \"\"\"Tries to read CSV bytes with a specific encoding in strict mode.\"\"\"\n",
    "    text = raw.decode(enc, errors=\"strict\")\n",
    "    sep = sniff_sep(text[:20000], default=',')\n",
    "    return pd.read_csv(io.StringIO(text), sep=sep)\n",
    "\n",
    "def try_read_bytes_relaxed(raw: bytes, enc: str):\n",
    "    \"\"\"Tries to read CSV bytes with a specific encoding in a more relaxed mode.\"\"\"\n",
    "    text = raw.decode(enc, errors=\"replace\")\n",
    "    sep = sniff_sep(text[:20000], default=',')\n",
    "    return pd.read_csv(\n",
    "        io.StringIO(text),\n",
    "        sep=sep,\n",
    "        engine=\"python\",\n",
    "        on_bad_lines=\"skip\",\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "        escapechar=\"\\\\\",\n",
    "    )\n",
    "\n",
    "def safe_read_csv(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Reads a CSV file by trying multiple encodings and parsing strategies.\"\"\"\n",
    "    encodings_try = [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin1\", \"iso-8859-1\", \"gb18030\", \"big5\"]\n",
    "    with open(path, \"rb\") as f:\n",
    "        raw = f.read()\n",
    "    # Try strict parsing first\n",
    "    for enc in encodings_try:\n",
    "        try:\n",
    "            df = try_read_bytes(raw, enc)\n",
    "            print(f\"[ok] Successfully parsed: {path} (encoding={enc})\")\n",
    "            return df\n",
    "        except Exception:\n",
    "            pass\n",
    "    # If strict fails, try relaxed parsing\n",
    "    for enc in encodings_try:\n",
    "        try:\n",
    "            df = try_read_bytes_relaxed(raw, enc)\n",
    "            print(f\"[ok] Successfully parsed in relaxed mode: {path} (encoding={enc})\")\n",
    "            return df\n",
    "        except Exception:\n",
    "            pass\n",
    "    # As a final fallback, use latin1 and ignore all errors\n",
    "    text = raw.decode(\"latin1\", errors=\"ignore\")\n",
    "    sep = sniff_sep(text[:20000], default=',')\n",
    "    df = pd.read_csv(io.StringIO(text), sep=sep, engine=\"python\", on_bad_lines=\"skip\",\n",
    "                     quoting=csv.QUOTE_NONE, escapechar=\"\\\\\")\n",
    "    print(f\"[ok] Successfully parsed with fallback: {path} (encoding=latin1, errors=ignore)\")\n",
    "    return df\n",
    "\n",
    "# ========= Case-insensitive Column Selector =========\n",
    "def colmap(df): return {c.lower(): c for c in df.columns}\n",
    "def pick(df, *cands):\n",
    "    \"\"\"Finds the first existing column from a list of candidates, ignoring case.\"\"\"\n",
    "    m = colmap(df)\n",
    "    for c in cands:\n",
    "        if c and c.lower() in m:\n",
    "            return m[c.lower()]\n",
    "    return None\n",
    "\n",
    "# ========= Read Data (fault-tolerant + multi-encoding) =========\n",
    "base = safe_read_csv(base_file)\n",
    "meta = safe_read_csv(meta_file)\n",
    "\n",
    "# Standardize the paper_id primary key\n",
    "pid_base_col = pick(base, \"paper_id\") or base.columns[0]\n",
    "pid_meta_col = pick(meta, \"paper_id\") or meta.columns[0]\n",
    "base[pid_base_col] = base[pid_base_col].astype(str).str.strip()\n",
    "meta[pid_meta_col] = meta[pid_meta_col].astype(str).str.strip()\n",
    "base = base.rename(columns={pid_base_col: \"paper_id\"})\n",
    "meta = meta.rename(columns={pid_meta_col: \"paper_id\"})\n",
    "\n",
    "# ========= Extract Required Fields from Meta (case-insensitive with aliases) =========\n",
    "# Attributes you want to keep:\n",
    "# 'paper_id','rate0','rate1','rate2','avg_score','decision','title','abstract','pdf_link'\n",
    "title_col    = pick(meta, \"title\")\n",
    "abstract_col = pick(meta, \"abstract\", \"abs\")\n",
    "rate0_col    = pick(meta, \"rate0\", \"rate_0\", \"r0\")\n",
    "rate1_col    = pick(meta, \"rate1\", \"rate_1\", \"r1\")\n",
    "rate2_col    = pick(meta, \"rate2\", \"rate_2\", \"r2\")\n",
    "avg_col      = pick(meta, \"avg_score\", \"average_score\", \"avg\")\n",
    "decision_col = pick(meta, \"decision\", \"decison\")  # Compatible with typo 'decison'\n",
    "pdf_col      = pick(meta, \"pdf_link\", \"link1\", \"pdf_url\", \"url\", \"pdf\")  # Compatible with 'link1'\n",
    "\n",
    "need_cols = [\"paper_id\"]\n",
    "rename_map = {}\n",
    "def add_if_exists(real_col_name, standard_col_name):\n",
    "    \"\"\"Adds a column to the list if it exists and maps it to a standard name.\"\"\"\n",
    "    if real_col_name is not None:\n",
    "        need_cols.append(real_col_name)\n",
    "        rename_map[real_col_name] = standard_col_name\n",
    "\n",
    "add_if_exists(rate0_col, \"rate0\")\n",
    "add_if_exists(rate1_col, \"rate1\")\n",
    "add_if_exists(rate2_col, \"rate2\")\n",
    "add_if_exists(avg_col, \"avg_score\")\n",
    "add_if_exists(decision_col, \"decision\")\n",
    "add_if_exists(title_col, \"title\")\n",
    "add_if_exists(abstract_col, \"abstract\")\n",
    "add_if_exists(pdf_col, \"pdf_link\")\n",
    "\n",
    "meta_reduced = meta[list(dict.fromkeys(need_cols))].copy().rename(columns=rename_map)\n",
    "\n",
    "# If avg_score is missing, calculate it from rate0/1/2 (ignoring NaN)\n",
    "if \"avg_score\" not in meta_reduced.columns:\n",
    "    for c in [\"rate0\", \"rate1\", \"rate2\"]:\n",
    "        if c in meta_reduced.columns:\n",
    "            meta_reduced[c] = pd.to_numeric(meta_reduced[c], errors=\"coerce\")\n",
    "    if all(c in meta_reduced.columns for c in [\"rate0\", \"rate1\", \"rate2\"]):\n",
    "        meta_reduced[\"avg_score\"] = np.nanmean(meta_reduced[[\"rate0\",\"rate1\",\"rate2\"]].values, axis=1)\n",
    "    else:\n",
    "        meta_reduced[\"avg_score\"] = np.nan\n",
    "\n",
    "# If meta has duplicate paper_ids, keep the first occurrence (as per requirement)\n",
    "meta_reduced = meta_reduced.drop_duplicates(subset=[\"paper_id\"], keep=\"first\")\n",
    "\n",
    "# ========= Left Join: Keep all paper_ids from the base file =========\n",
    "enriched = base.merge(meta_reduced, on=\"paper_id\", how=\"left\")\n",
    "\n",
    "# ========= Match Statistics =========\n",
    "fields = [\"title\", \"abstract\", \"rate0\", \"rate1\", \"rate2\", \"avg_score\", \"decision\", \"pdf_link\"]\n",
    "present_cols = [c for c in fields if c in enriched.columns]\n",
    "def _nonempty(s): return s.notna() & (s.astype(str).str.strip() != \"\")\n",
    "\n",
    "if present_cols:\n",
    "    matched_any = np.zeros(len(enriched), dtype=bool)\n",
    "    for c in present_cols:\n",
    "        matched_any |= _nonempty(enriched[c])\n",
    "else:\n",
    "    matched_any = np.zeros(len(enriched), dtype=bool)\n",
    "\n",
    "total_base = len(enriched)\n",
    "matched_count = int(matched_any.sum())\n",
    "unmatched_count = total_base - matched_count\n",
    "\n",
    "print(\"✅ Merge complete\")\n",
    "print(\"Total rows in base table:\", total_base)\n",
    "print(\"Rows with at least one matched field:\", matched_count)\n",
    "print(\"Rows with no matched fields:\", unmatched_count)\n",
    "\n",
    "# Export list of unmatched items (paper_id only)\n",
    "if unmatched_count > 0:\n",
    "    enriched.loc[~matched_any, [\"paper_id\"]].drop_duplicates().to_csv(unmatched_out, index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"List of unmatched IDs saved to:\", unmatched_out)\n",
    "else:\n",
    "    print(\"Unmatched items: None\")\n",
    "\n",
    "# ========= Save Final Result =========\n",
    "# Ensure the final DataFrame has a consistent column order\n",
    "final_columns_order = [\n",
    "    \"paper_id\", \"section_count\", \"introduction\", \"conclusion\", \"rate0\", \"rate1\",\n",
    "    \"rate2\", \"avg_score\", \"decision\", \"title\", \"abstract\", \"pdf_link\"\n",
    "]\n",
    "# Only include columns that actually exist in the DataFrame\n",
    "final_columns_existing = [col for col in final_columns_order if col in enriched.columns]\n",
    "enriched = enriched[final_columns_existing]\n",
    "\n",
    "enriched.to_csv(out_file, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Output file:\", out_file)\n",
    "\n",
    "\n",
    "# ========= Optional: Null value statistics =========\n",
    "# Check which paper_ids have null/empty values in specified fields\n",
    "check_cols = [\n",
    "    \"paper_id\",\"section_count\",\"introduction\",\"conclusion\",\n",
    "    \"rate0\",\"rate1\",\"rate2\",\"avg_score\",\"decision\",\"title\",\"abstract\",\"pdf_link\"\n",
    "]\n",
    "\n",
    "empty_records = {}\n",
    "\n",
    "for col in check_cols:\n",
    "    if col not in enriched.columns:\n",
    "        continue\n",
    "    # Check for NaN or whitespace-only strings\n",
    "    mask = enriched[col].isna() | (enriched[col].astype(str).str.strip() == \"\")\n",
    "    if mask.any():\n",
    "        empty_records[col] = enriched.loc[mask, \"paper_id\"].tolist()\n",
    "        print(f\"⚠️ Column '{col}' has {mask.sum()} null or empty values\")\n",
    "        # Print only the first 10 examples\n",
    "        print(\"Examples of corresponding paper_ids:\", empty_records[col][:10])\n",
    "    else:\n",
    "        print(f\"✅ Column '{col}' has no null values\")\n",
    "\n",
    "# Save the full list of empty/null records to a file\n",
    "out_missing = r\"E:\\judita's project\\new data 2\\missing_paper_ids_by_field.json\"\n",
    "with open(out_missing, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(empty_records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Full list of empty/null records has been exported to:\", out_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "deaecf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Filling complete, saved to: E:\\judita's project\\new data 2\\paper_id_intro_conclusion_enriched_filled.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ===== 1. 读取原始数据文件 =====\n",
    "file_path = r\"E:\\judita's project\\new data 2\\paper_id_intro_conclusion_enriched.csv\"\n",
    "df = pd.read_csv(file_path, encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "\n",
    "# ===== 2. 定义需要手动填补的内容 =====\n",
    "intro_fill = {\n",
    "    \"7R7fAoUygoa\": \"\"\"Recent works have demonstrated a ubiquitous “double descent” phenomenon present in a range\n",
    "of machine learning models, including decision trees, random features, linear regression, and deep\n",
    "neural networks (Opper, 1995; 2001; Advani & Saxe, 2017; Spigler et al., 2018; Belkin et al., 2018;\n",
    "Geiger et al., 2019b; Nakkiran et al., 2020; Belkin et al., 2019; Hastie et al., 2019; Bartlett et al.,\n",
    "2019; Muthukumar et al., 2019; Bibas et al., 2019; Mitra, 2019; Mei & Montanari, 2019; Liang &\n",
    "Rakhlin, 2018; Liang et al., 2019; Xu & Hsu, 2019; Derezinski et al., 2019; Lampinen & Ganguli, ´\n",
    "2018; Deng et al., 2019; Nakkiran, 2019). The phenomenon is that models exhibit a peak of high\n",
    "test risk when they are just barely able to fit the train set, that is, to interpolate. For example, as we\n",
    "increase the size of models, test risk first decreases, then increases to a peak around when effective\n",
    "model size is close to the training data size, and then decreases again in the overparameterized\n",
    "regime. Also surprising is that Nakkiran et al. (2020) observe a double descent as we increase\n",
    "sample size, i.e. for a fixed model, training the model with more data can hurt test performance.\n",
    "These striking observations highlight a potential gap in our understanding of generalization and\n",
    "an opportunity for improved methods. Ideally, we seek to use learning algorithms which robustly\n",
    "improve performance as the data or model size grow and do not exhibit such unexpected non monotonic behaviors. In other words, we aim to improve the test performance in situations which\n",
    "would otherwise exhibit high test risk due to double descent. Here, a natural strategy would be to\n",
    "use a regularizer and tune its strength on a validation set. This motivates the central question of this\n",
    "work:\n",
    "When does optimally tuned regularization mitigate or remove the double-descent phenomenon?\n",
    "Another motivation is the fact that double descent is largely observed for unregularized or under regularized models in practice. As an example, Figure 1 shows a simple linear ridge regression\n",
    "setting in which the unregularized estimator exhibits double descent, but an optimally-tuned regu larizer has monotonic test performance.\n",
    "Our Contributions: We study this question from both a theoretical and empirical perspective.\n",
    "Theoretically, we start with the setting of high-dimensional linear regression. Linear regression is\n",
    "a sensible starting point to study these questions, since it already exhibits many of the qualitative\n",
    "features of double descent in more complex models (e.g. Belkin et al. (2019); Hastie et al. (2019)\n",
    "and further related works in Section 1.1). Our work shows that optimally-tuned ridge regression can\n",
    "achieve both sample-wise monotonicity and model-size-wise monotonicity under certain assump tions. Concretely, we show\n",
    "1. Sample-wise monotonicity: In the setting of well-specified linear regression with isotropic\n",
    "features/covariates (Figure 1), we prove that optimally-tuned ridge regression yields monotonic test\n",
    "performance with increasing samples. That is, more data never hurts for optimally-tuned ridge\n",
    "regression. (See Theorem 1).\n",
    "2. Model-wise monotonicity: We consider a setting where the input/covariate lives in a high dimensional ambient space with isotropic covariance. Given a fixed model size d (which might be\n",
    "much smaller than ambient dimension), we consider the family of models which first project the\n",
    "input to a random d-dimensional subspace, and then compute a linear function in this projected\n",
    "“feature space.” (This is nearly identical to models of double-descent considered in Hastie et al.\n",
    "(2019, Section 5.1)). We prove that in this setting, as we grow the model-size, optimally-tuned\n",
    "ridge regression over the projected features has monotone test performance. That is, with optimal\n",
    "regularization, bigger models are always better or the same. (See Theorem 3).\n",
    "3. Monotonicity in the real-world: We also demonstrate several richer empirical settings where\n",
    "optimal ` 2 regularization induces monotonicity, including random feature classifiers and convolu tional neural networks. This suggests that the mitigating effect of optimal regularization may hold\n",
    "more generally in broad machine learning contexts. (See Section 5).\n",
    "A few remarks are in order:\n",
    "Problem-specific vs Minimax and Bayesian. It is worth noting that our results hold for all linear\n",
    "ground-truths, rather than holding for only the worst-case ground-truth or a random ground-truth.\n",
    "Indeed, the minimax optimal estimator or the Bayes optimal estimator are both trivially sample-wise\n",
    "and model-wise monotonic with respect to the minimax risk or the Bayes risk. However, they do not\n",
    "guarantee monotonicity of the risk itself for a given fixed problem. In particular, there exist minimax\n",
    "optimal estimators which are not sample-monotonic in the sense we desire.\n",
    "Universal vs Asymptotic. We also remark that our analysis is not only non-asymptotic but also\n",
    "works for all possible input dimensions, model sizes, and sample sizes. To our knowledge, the\n",
    "results herein are the first non-asymptotic sample-wise and model-wise monotonicity results for\n",
    "linear regression. (See discussion of related works Hastie et al. (2019); Mei & Montanari (2019)\n",
    "for related results in the asymptotic setting). Our work reveals aspects of the problem that were not\n",
    "present in prior asymptotic works. For example, we empirically show that optimal regularization\n",
    "can eliminate even “triple descent” in ridge regression (Figure 2). Moreover, we show that for non Gaussian covariates, optimally-tuned ridge regression is not always sample-monotonic: we give a\n",
    "counterexample in Section 4.\n",
    "Towards a more general characterization. Our theoretical results crucially rely on the covariance\n",
    "of the data being isotropic. A natural next question is if and when the same results can hold more\n",
    "generally. A full answer to this question is beyond the scope of this paper, though we give the\n",
    "following results:\n",
    "1. Optimally-tuned ridge regression is not always sample-monotonic: we show a counterex ample for a certain non-Gaussian data distribution and heteroscedastic noise. We are not\n",
    "aware of prior work pointing out this fact. (See Section 4 for the counterexample and\n",
    "intuitions.)\n",
    "2. For non-isotropic Gaussian covariates, we can achieve sample-wise monotonicity with a\n",
    "regularizer that depends on the population covariance matrix of data. This suggests unla beled data might also help mitigate double descent in some settings, because the population\n",
    "covariance can be estimated from unlabeled data. (See Appendix B).\n",
    "3. For non-isotropic Gaussian covariates, we conjecture that optimally-tuned ridge regression\n",
    "is sample-monotonic even with a standard ` 2 regularizer (as in Figure 2). We derive a\n",
    "sufficient condition for this conjecture. Due to that current random matrix theory may be\n",
    "insufficient to verify this conjecture, we verify it numerically on a wide variety of cases.\n",
    "(See Appendix B for details).\n",
    "The last two results above highlight the importance of the form of the regularizer, which leads to the\n",
    "open question: “How do we design good regularizers which mitigate or remove double descent?”\n",
    "We hope that our results can motivate future work on mitigating the double descent phenomenon,\n",
    "and allow us to train high performance models which do not exhibit nonmonotonic behaviors.\n",
    "1.1 RELATED WORKS\n",
    "The study of nonmonotonicity in learning algorithms existed prior to double descent and has a long\n",
    "history going back to (at least) Trunk (1979) and LeCun et al. (1991); Le Cun et al. (1991), where the\n",
    "former was largely empirical observations and the latter studied the sample non-nonmonotonicity of\n",
    "unregularized linear regression in terms of the eigenspectrum of the covariance matrix; the difference\n",
    "to our works is that we study this in the context of optimal regularization. In fact, Duin (1995;\n",
    "2000); Opper (2001); Loog & Duin (2012). Loog et al. (2019) introduces the same notion of risk\n",
    "monotonicity which we consider, and studies several examples of monotonic and non-monotonic\n",
    "procedures.\n",
    "Double descent of test risk as a function of model size was considered recently in more generality\n",
    "by Belkin et al. (2018). Similar behavior was observed empirically in earlier work in somewhat\n",
    "more restricted settings Trunk (1979); Opper (1995; 2001); Skurichina & Duin (2002); Le Cun et al.\n",
    "(1991); LeCun et al. (1991) and more recently in Advani & Saxe (2017); Geiger et al. (2019a);\n",
    "Spigler et al. (2018); Neal et al. (2018). Recently Nakkiran et al. (2020) demonstrated a generalized\n",
    "double descent phenomenon on modern deep networks, and highlighted “sample non-monotonicity”\n",
    "as an aspect of double descent.\n",
    "A recent stream of theoretical works consider model-wise double descent in simplified settings—\n",
    "often via linear models for regression or classification. This also connects to works on high dimentional regression in the statistics literature. A partial list of works in these areas include\n",
    "Belkin et al. (2019); Hastie et al. (2019); Bartlett et al. (2019); Muthukumar et al. (2019); Bibas\n",
    "et al. (2019); Mitra (2019); Mei & Montanari (2019); Liang & Rakhlin (2018); Liang et al. (2019);\n",
    "Xu & Hsu (2019); Derezinski et al. (2019); Lampinen & Ganguli (2018); Deng et al. (2019); Nakki- ´\n",
    "ran (2019); Mahdaviyeh & Naulet (2019); Dobriban et al. (2018); Dobriban & Sheng (2019); Kobak\n",
    "et al. (2018). Of these, most closely related to our work are Hastie et al. (2019); Dobriban et al.\n",
    "(2018); Mei & Montanari (2019). Specifically, Hastie et al. (2019) considers the risk of unregular ized and regularized linear regression in an asymptotic regime, where dimension d and number of\n",
    "samples n scale to infinity together, at a constant ratio d/n. In contrast, we show non-asymptotic\n",
    "results, and are able to consider increasing the number of samples for a fixed model, without scaling\n",
    "both together. Mei & Montanari (2019) derive similar results for unregularized and regularized ran\u0002dom features, also in an asymptotic limit. The non-asymptotic versions of the settings considered in\n",
    "Hastie et al. (2019) are almost identical to ours— for example, our projection model in Section 3 is\n",
    "nearly identical to the model in Hastie et al. (2019, Section 5.1). Finally, subsequent to our work,\n",
    "d’Ascoli et al. (2020) identified triple descent in an asymptotic setting.\"\"\",\n",
    "    \"D9I3drBz4UC\": \"\"\"Real-world data are often long-tail distributed over semantic classes: A few classes contain many\n",
    "instances, whereas most classes contain only a few instances. Long-tailed recognition is challenging,\n",
    "as it needs to handle not only a multitude of small-data learning problems on the tail classes, but\n",
    "also extreme imbalanced classification over all the classes.\n",
    "There are two ways to prevent the many head instances from overwhelming the few tail instances in\n",
    "the classifier training objective: 1) class re-balancing/re-weighting which gives more importance\n",
    "to tail instances (Cao et al., 2019; Kang et al., 2020; Liu et al., 2019), 2) ensembling over different\n",
    "data distributions which re-organizes long-tailed data into groups, trains a model per group, and\n",
    "then combines individual models in a multi-expert framework (Zhou et al., 2020; Xiang et al., 2020).\n",
    "We compare three state-of-the-art (SOTA) long-tail classifiers against the standard cross-entropy\n",
    "(CE) classifier: cRT and τ -norm (Kang et al., 2020) which adopt a two-stage optimization, first rep resentation learning and then classification learning, and LDAM (Cao et al., 2019), which is trained\n",
    "end-to-end with a marginal loss. In terms of the classification accuracy, a common metric for model\n",
    "selection on a fixed training set, Fig. 1a shows that, all these existing long-tail methods increase the\n",
    "overall, medium- and few-shot accuracies over CE, but decrease the many-shot accuracy.\n",
    "These intuitive solutions and their experimental results seem to suggest that there is a head-tail per formance trade-off in long-tailed recognition. We need a principled performance analysis approach\n",
    "that could shed light on such a limitation if it exists and provide guidance on how to overcome it.\n",
    "Our insight comes from a dynamic view of the training set: It is merely a sample set of some underly ing data distribution. Instead of evaluating how a long-tailed classifier performs on the fixed training\n",
    "set, we evaluate how it performs as the training set fluctuates according to the data distribution.\n",
    "\n",
    "Consider the training data D as a random variable. The prediction error of model h on instance x\n",
    "with output Y varies with the realization of D. The expected variance with respect to variable D\n",
    "has a well-known bias-variance decomposition:\n",
    "Error(x; h) = E[(h(x; D) − Y )2] = Bias(x; h) + Variance(x; h) + irreducible error(x). (1)\n",
    "For the above L2 loss on regression h(x) → Y , the model bias measures the accuracy of the pre diction with respect to the true value, the variance measures the stability of the prediction, and the\n",
    "irreducible error measures the precision of the prediction and is irrelevant to the model h.\n",
    "As shown on the above right, these concepts can be expressed entirely in terms of L2 loss L. We can\n",
    "thus extended them to classification (Domingos, 2000) by replacing L with L0-1 for classification:\n",
    "We apply such bias and variance analysis to the CE and long-tail classifiers. We sample CIFAR100\n",
    "(Krizhevsky, 2009) according to a long-tail distribution multiple times. For each method, we train\n",
    "a model per long-tail sampled dataset and then estimate the per-class bias and variance over these\n",
    "multiple models on the balanced test set of CIFAR100-LT Liu et al. (2019). Fig. 1a shows that:\n",
    "1. On the model bias: The head bias is significantly smaller than the tail bias, at 0.3 vs. 0.9 for\n",
    "CE. All the existing long-tail methods reduce the overall bias by primarily reducing the tail bias.\n",
    "However, the head-tail bias gap remains large at 0.3 vs. 0.8.\n",
    "2. On the model variance: All the existing long-tail methods increase the model variance across\n",
    "all class splits, with a slight reduction in the medium-shot variance for cRT.\n",
    "That is, existing long-tail methods reduce the model bias for the tail at the cost of increased model\n",
    "variance for all the classes, and the head-tail model bias gap remains large.\n",
    "We conduct further statistical analysis to understand the head-tail model bias gap. We examine the\n",
    "largest softmax score in the other classes of {c : c = t}, where t is the ground-truth class of an\n",
    "instance. The smaller this hardest negative score is, the less the confusion, and the lower the model\n",
    "bias. Fig. 1b shows that there is increasingly more and larger confusion from the head to the tail.\n",
    "Guided by our model bias/variance and confusion pattern analysis, we propose a new long-tail clas\u0002sifier with four distinctive features: 1) It reduces the model variance for all the classes with multiple\n",
    "experts. 2) It reduces the model bias for the tail with an additional distribution-aware diversity loss.\n",
    "3) It reduces the computational complexity that comes with multiple experts with a dynamic expert\n",
    "routing module which deploys another trained distinctive expert for a second (or third, ...) opinion\n",
    "only when it is called for. 4) The routing module and a shared architecture for experts of reduced\n",
    "complexity effectively cut down the computational cost of our multi-expert model, to a level that\n",
    "could be even lower than the commonly adopted baseline with the same backbone.\n",
    "Our so-called RoutIng Diverse Experts (RIDE) not only reduces the model variance for all the\n",
    "classes, but also significantly reduces the model bias for the tail classes and increases the mean\n",
    "accuracies for all class splits, all of which existing long-tail methods fail to accomplish.\n",
    "RIDE delivers 5%∼7% higher accuracies than the current SOTA methods on CIFAR100-LT,\n",
    "ImageNet-LT (Liu et al., 2019) and iNaturalist (Van Horn et al., 2018). RIDE is also a universal\n",
    "framework that can be applied to different backbone networks for improving existing long-tail algo\u0002rithms such as focal loss (Lin et al., 2017), LDAM (Cao et al., 2019), τ -norm (Kang et al., 2020)\"\"\",\n",
    "    \"Fj1Tpym9KxH\": \"\"\"Domain Adversarial Training (Ganin & Lempitsky, 2015) (DAT) refers to adversarial learning of\n",
    "neural network based feature representations that are invariant to the domain. For example, car\n",
    "images from the clipart domain have similar feature representations as car images from the web\n",
    "domain. DAT has been widely useful in diverse areas (cited 3540 times) such as fairness (Adel\n",
    "et al., 2019), object detection (Saito et al., 2019), domain generalization (Li et al., 2018), image to-image translation (Liu et al., 2017) etc. The prime driver of research on DAT is its application\n",
    "in unsupervised Domain Adaptation (DA), which aims to learn a classifier using labeled source\n",
    "data and unlabeled target data, such that it generalizes well on target data. Various enhancements\n",
    "like superior objectives (Acuna et al., 2021; Zhang et al., 2019), architectures (Long et al., 2018)\n",
    "etc. have been proposed to improve its effectiveness. However, as DAT objective is combination of\n",
    "Generative Adversarial Network (GAN) (Goodfellow et al., 2014) and Empirical Risk Minimization\n",
    "(ERM) (Vapnik, 2013) objectives, there has not been much focus on explicitly analyzing the nature\n",
    "of optimization in DAT. One direction of work aiming to improve generalization of ERM on unseen\n",
    "data focuses on developing algorithms that converge to a smooth (or a flat) minima (Foret et al.,\n",
    "2021; Keskar & Socher, 2017). However, we find that these techniques, when directly applied for\n",
    "DAT, do not significantly improve the generalization on the target domain (Sec. 4 and 7).\n",
    "In this work, we analyze the loss landscape near the optimal point obtained by DAT, to gain insights\n",
    "into curvature. We first focus on the eigen-spectrum of Hessian of the task loss (ERM term for\n",
    "classification) where we find that using Stochastic Gradient Descent (SGD) as optimizer converges\n",
    "to a smoother minima in comparison to Adam (Kingma & Ba, 2014). Further we find that smoother\n",
    "minima w.r.t.task loss leads to better generalization on the target domain. Contrary to task loss,\n",
    "we find that smoothness enhancing formulation for adversarial components worsen performance,\n",
    "rendering ERM-based techniques which enhance smoothness for all loss components ineffective.\n",
    "Hence we introduce Smooth Domain Adversarial Training (SDAT), which aims only to reach a\n",
    "smooth minima w.r.t. task loss, and helps in generalizing better on the target domain. SDAT requires\n",
    "an additional gradient computation step and can be combined with existing methods with a few lines\n",
    "of code. We show the soundness of the SDAT method theoretically by proving a generalization\n",
    "bound (Sec. 4) on target error. We extensively verify the empirical efficacy of SDAT across various\n",
    "datasets for classification (i.e., DomainNet, VisDA-2017 and Office-Home), along with showing\n",
    "a prototypical application in DA for object detection, demonstrating it’s diverse applicability. In\n",
    "summary, we make the following contributions:\n",
    "• We analyze the optimization procedure of DAT, establishing the correlation between the\n",
    "smoothness near optima w.r.t. task loss and generalization on the target domain.\n",
    "• Contrary to ERM, we show through our theoretical and empirical analysis that smoothness\n",
    "enhancing adversarial formulation leads to sub-optimal performance.\n",
    "• For enhancing the smoothness w.r.t. task loss near optima in DAT, we propose a novel and\n",
    "theoretically motivated SDAT that improves the generalization on the target domain. SDAT\n",
    "effectively increases the average performance of even state-of-the-art adversarial adaptation\n",
    "methods.\"\"\",\n",
    "    \"FvfV64rovnY\": \"\"\"For a large variety of models and datasets, neural network performance has been empirically observed\n",
    "to scale as a power-law with model size and dataset size (Hestness et al., 2017; Kaplan et al., 2020;\n",
    "Rosenfeld et al., 2020b; Henighan et al., 2020). These exponents determine how quickly performance\n",
    "improves with more data and larger models. We would like to understand why these power-laws\n",
    "emerge, and what features of the data and models determine the values of the power law exponents.\n",
    "In this work, we present a theoretical framework for understanding scaling laws in trained neural\n",
    "networks. We identify four related scaling regimes with respect to the number of model parameters\n",
    "P and the dataset size D. With respect to each of D, P, there is both a variance-limited regime and a\n",
    "resolution-limited regime.\n",
    "Variance-Limited Regime In the limit of infinite data or an arbitrarily wide model, some aspects\n",
    "of neural network training simplify. Specifically, if we fix one of D, P and study scaling with respect\n",
    "to the other parameter as it becomes arbitrarily large, then the difference between the finite test loss\n",
    "and its limiting value scales as 1/x, i.e. as a power-law with exponent 1, with x = D or √\n",
    "P ∝ width\n",
    "in deep networks and x = D or P in linear models.\n",
    "Resolution-Limited Regime In this regime, one of D or P is effectively infinite, and we study\n",
    "scaling as the other parameter increases. In this case, a variety of works have empirically observed\n",
    "power-law scalings 1/xα, typically with 0 < α < 1 for both x = P or D. We derive exponents in\n",
    "this regime precisely in the setting of random feature models (c.f. next section). Empirically, we find\n",
    "that our theoretical predictions for exponents hold in pretrained, fine-tuned models even though these\n",
    "lie outside our theoretical setting.\n",
    "For more general nonlinear models, we propose a refinement of naive bounds into estimates via\n",
    "expansions that hold asymptotically. These rely on the idea that additional data (in the infinite\n",
    "model-size limit) or added model parameters (in the infinite data limit) are used by the model to\n",
    "carve up the data manifold into smaller components. For smooth manifolds, loss, and network, the\n",
    "test loss will depend on the linear size of a sub-region, while it is the d-dimensional sub-region\n",
    "volume that scales inversely with P or D, giving rise to α ∝ 1/d.\n",
    "1 To test this empirically, we make\n",
    "measurements of the resolution-limited exponents in neural networks and intrinsic dimension of the\n",
    "data manifold, shown in Figure 1b.\n",
    "Explicit Derivation We derive the scaling laws for these four regimes explicitly in the setting of\n",
    "random feature teacher-student models, which also applies to neural networks in the large width limit.\n",
    "This setting allows us to solve for the test error directly in terms of the feature covariance (kernel).\n",
    "The scaling of the test loss then follows from the asymptotic decay of the spectrum of the covariance\n",
    "matrix. For generic continuous kernels on a d-dimensional manifold, we can further relate this to the\n",
    "dimension of the data manifold.\n",
    "Summary of Contributions:\n",
    "1. We propose four scaling regimes for neural networks. The variance-limited and resolution limited regimes originate from different mechanisms, which we identify. To our knowledge,\n",
    "this categorization has not been previously exhibited. We provide empirical support for all four\n",
    "regimes in deep networks on standard datasets.\n",
    "2. We derive the variance-limited regime under simple yet general assumptions (Theorem 1).\n",
    "3. We present a hypothesis for resolution-limited scaling through refinement of naive bounds (Theo\u0002rems 2, 3), for general nonlinear models. We empirically test the dependence of the estimates on\n",
    "intrinsic dimension of the data manifold for deep networks on standard datasets (Figure 1b).\n",
    "4. In the setting of random feature teacher-student networks, we derive both variance-limited and\n",
    "resolution-limited scaling exponents exactly. In the latter case, we relate this to the spectral decay\n",
    "of kernels. We identify a novel duality that exists between model and dataset size scaling.\n",
    "5. We empirically investigate predictions from the random features setting in pretrained, fine-tuned\n",
    "models on standard datasets and find they give excellent agreement.\n",
    "6. We study the dependence of the scaling exponent on changes in architecture and data, finding that\n",
    "(i) changing the input distribution via switching datasets and (ii) the addition of noise have strong\n",
    "effects on the exponent, while (iii) changing the target task via superclassing does not.\n",
    "Related Works: There have been a number of recent works demonstrating empirical scaling laws\n",
    "(Hestness et al., 2017; Kaplan et al., 2020; Rosenfeld et al., 2020b; Henighan et al., 2020; Rosenfeld\n",
    "et al., 2020a) in deep neural networks, including scaling laws with model size, dataset size, compute,\n",
    "and other observables such as mutual information and pruning. Some precursors (Ahmad & Tesauro,\n",
    "1989; Cohn & Tesauro, 1991) can be found in earlier literature. Recently, scaling laws have also\n",
    "played a significant role in motivating work on the largest models that have yet been developed\n",
    "(Brown et al., 2020; Fedus et al., 2021).\n",
    "There has been comparatively little work on theoretical ideas (Sharma & Kaplan, 2020; Bisla et al.,\n",
    "2021) that match and explain empirical findings in generic deep neural networks. In the particular\n",
    "case of large width, deep neural networks behave as random feature models (Neal, 1994; Lee et al.,\n",
    "2018; Matthews et al., 2018; Jacot et al., 2018; Lee et al., 2019; Dyer & Gur-Ari, 2020), and known\n",
    "results on the loss scaling of kernel methods can be applied (Spigler et al., 2020; Bordelon et al.,\n",
    "2020). Though not in the original, Bordelon et al. (2020) analyze resolution-limited dataset size\n",
    "scaling for power-law spectra in later versions.\n",
    "During the completion of this work, Hutter (2021) presented a specific solvable model of learning\n",
    "exhibiting non-trivial power-law scaling for power-law (Zipf) distributed features. This does not\n",
    "directly relate to the setups studied in this work, or present bounds that supersede our results.\n",
    "Concurrent to our work, Bisla et al. (2021) presented a derivation of the resolution-limited scaling\n",
    "with dataset size, also stemming from nearest neighbor distance scaling on data manifolds. However,\n",
    "they do not discuss requirements on model versus dataset size or how this scaling behavior fits into\n",
    "other asymptotic scaling regimes.\n",
    "In the variance-limited regime, scaling laws in the context of random feature models (Rahimi &\n",
    "Recht, 2008; Hastie et al., 2019; d’Ascoli et al., 2020), deep linear models (Advani & Saxe, 2017;\n",
    "Advani et al., 2020), one-hidden-layer networks (Mei & Montanari, 2019; Adlam & Pennington,\n",
    "2020a;b), and wide neural networks treated as Gaussian processes or trained in the NTK regime\n",
    "(Lee et al., 2019; Dyer & Gur-Ari, 2020; Andreassen & Dyer, 2020; Geiger et al., 2020) have been\n",
    "studied. In particular, this behavior was used in (Kaplan et al., 2020) to motivate a particular ansatz\n",
    "for simultaneous scaling with data and model size. The resolution-limited analysis can perhaps be\n",
    "viewed as an attempt to quantify the ideal-world generalization error of Nakkiran et al. (2021).\n",
    "This work makes use of classic results connecting the spectrum of a smooth kernel to the geometry\n",
    "it is defined over (Weyl, 1912; Reade, 1983; Kuhn, 1987; Ferreira & Menegatto, 2009) and on the ¨\n",
    "scaling of iteratively refined approximations to smooth manifolds (Stein, 1999; Bickel et al., 2007;\n",
    "de Laat, 2011).\"\"\"\n",
    ",\n",
    "    \"RVhzamxHBjP\": \"\"\"1.1 INVERSE PROBLEMS AND DEEP LEARNING\n",
    "For many physical systems, we observe only the output and strive to infer the input. The inference\n",
    "task is often captured by the generic term “inverse problem”. Formally, the underlying system\n",
    "is modeled by a forward mapping f, and solving the inverse problem amounts to identifying the\n",
    "inverse mapping f−1. Inverse problems abound in numerous fields and take diverse forms, see,\n",
    "e.g., (Hartley & Zisserman, 2003; Gonzalez & Woods, 2017; Comon, 2010; Colton & Kress, 2013;\n",
    "Herman, 2009; Entekhabi et al., 1994; Ge, 2013). Let y denote the observed output. Traditionally,\n",
    "inverse problems are mostly formulated as regularized optimization problems of the form\n",
    "minx(y, f(x)) + λΩ(x), (1.1)\n",
    "where x represents the input to be estimated, (y, f(x)) ensures y ≈ f(x) (` means loss), Ω(x)\n",
    "encodes prior knowledge about x—often added to make the problem well-posed, and λ is a tradeoff\n",
    "parameter. To solve Eq. (1.1) , iterative numerical algorithms are often developed (Kirsch, 2011).\n",
    "Deep learning has enabled learning data-driven loss ` or Ω, or replacing mappings in iterative meth ods for solving Eq. (1.1) by data-adaptive ones. These ideas can capture structures in practical data\n",
    "not expressible before and tend to lead to faster and/or more effective algorithms. Most radical\n",
    "is perhaps the end-to-end approach: a deep neural network (DNN) is directly set up and trained\n",
    "to approximate the inverse mapping f\n",
    "−1—backed by the famous universal approximation theo rem (Poggio et al., 2017) and based on a sufficiently large set of (x, y) pairs. Instead of citing the\n",
    "abundance of individual papers, we refer the reader to the excellent review articles (McCann et al.,\n",
    "2017; Lucas et al., 2018; Arridge et al., 2019; Ongie et al., 2020b) on these developments.\n",
    "1.2 DIFFICULTY WITH SYMMETRIES\n",
    "In this paper, we focus on the end-to-end learning approach. This approach has recently been widely\n",
    "acclaimed for its remarkable performance on several tasks such as image denoising (Xie et al.,\n",
    "2012), image super-resolution (Dong et al., 2014), image deblurring (Xu et al., 2014), and sparse\n",
    "recovery (Mousavi & Baraniuk, 2017). In these examples, f is linear.\n",
    "When f is nonlinear, intrinsic symmetries appear in many problems. A couple of quick examples:\n",
    "• Fourier phase retrieval (PR) The forward model is Y = |F(X)|2, where X ∈ Cn×n andY ∈ Rm×m are matrices and F is the 2D (oversampled) Fourier transform. The operation\n",
    "|·| takes elementwise complex magnitudes. It is well known that translations to the non\u0002zero part of X (if feasible), conjugate flipping of X, and global phase transfer e\n",
    "iθX forany θ ∈ [0, 2π) all lead to the same Y (Bendory et al., 2017).\n",
    "• Blind deconvolution The forward model is y = a ~ x, where a is the convolution kernel,\n",
    "x is the signal (e.g., image) of interest, and ~ denotes the circular convolution. Both a and\n",
    "x are inputs. Here, a ~ x = (λa) ~ (x/λ) for any λ = 0, and circularly shifting a to the\n",
    "left and shifting x to the right by the same amount does not change y (Lam & Goodman,\n",
    "2000; Tonellot & Broadhead, 2010)\n",
    "Solving these inverse problems means recovering the input up to the intrinsic system symmetries, as\n",
    "evidently this is the best one can hope for.\n",
    "Symmetries can cause significant difficulty for\n",
    "the end-to-end approach. To see this, suppose\n",
    "we randomly sample real values xi’s and form a\n",
    "training set \b xi, x2iand try to learn the square\u0002root function, allowing both positive and neg\u0002ative outputs, using the end-to-end approach.\n",
    "Now if we think of the function determined by\n",
    "the training set, which the neural network is try\u0002ing to approximate, it is highly oscillatory (see\n",
    "Fig. 1)1\n",
    ": the sign symmetry dictates that in the\n",
    "training set, there are frequent cases where x2I and x2j are close but xi and xj have different\n",
    "signs and are far apart. Although in theory neu\u0002ral networks with adequate capacity are univer\u0002sal function approximators, in practice they will\n",
    "struggle to learn such irregular functions. For general inverse problems, so long as the forward sym\u0002metries can relate remote inputs to the same output, similar problems can surface.\n",
    "1.3 OUR CONTRIBUTION: SYMMETRY BREAKING\n",
    "An easy fix to the above issue is fixing all signs of xi’s to be positive (or negative), which we call\n",
    "“symmetry breaking”. We generalize this and\n",
    "• Take phase retrieval (PR) as an example to show how symmetry breaking can be performed\n",
    "and how this can lead to substantial gain in performance. For PR, our algorithm solves the\n",
    "problem in a regime not accessible by previous methods.\n",
    "• Identify the basic principle of effective symmetry breaking, which can be readily applied\n",
    "to other inverse problems with symmetries.\"\"\"\n",
    "}\n",
    "\n",
    "conclusion_fill = {\n",
    "    \"VNJUTmR-CaZ\": \n",
    "\"\"\"In this paper, we proposed a new graph neural network architecture, called CAM, for a multi\u0002robot task allocation problem with a set of com\u0002plexities, including tasks with time deadline and robots with ferry range and payload capacity con\u0002straints. This new architecture incorporates an encoder based on covariant node-based embed\u0002ding and a decoder based on attention mecha\u0002nism. To learn the features of the encoder and decoder, the problem has been imposed as a re\u0002inforcement learning problem and it has been solved using a policy simple gradient algorithm, REINFORCE. In addition, to compare the per\u0002formance of the proposed CAM method, an attention-based approach (aka AM) has been ex\u0002tended to be able to handle a multi-agent combi\u0002natorial optimization problem (i.e., a multi-robot task allocation problem).To evaluate the performance of the proposed architecture, and the extended version of AM are\n",
    "trained for 200 epochs and tested on 100 unseen case studies. Performance was analyzed in terms of\n",
    "cost function and completion rate. The new proposed architecture showed a better sample efficiency\n",
    "than AM by reaching a better cost value only after 7 epochs versus 73 epochs of AM. Our primary\n",
    "method, CAM, outperformed the AM approach by achieving (up to) 84% better cost function value\n",
    "(in term of the mean value). The computational cost analysis showed that the proposed CAM model\n",
    "takes a few milliseconds to take a decision; hence, it is an excellent choice for online decision making\n",
    "(here, task allocation). A further study on the performance of both AM and CAM approaches on\n",
    "case studies with different number of tasks demonstrated that our proposed CAM method is superior\n",
    "to AM in all case studies. While the current method is operational over varying task size (the upper\n",
    "bound is the number of tasks that model has been trained on), it is not invariant to the size of swarm.\n",
    "One immediate future work is to expend the architecture to have a swarm size invariant model.\"\"\"\n",
    "}\n",
    "\n",
    "# ===== 3. 对 DataFrame 进行字段更新 =====\n",
    "for pid, text in intro_fill.items():\n",
    "    df.loc[df['paper_id'] == pid, 'introduction'] = text\n",
    "\n",
    "for pid, text in conclusion_fill.items():\n",
    "    df.loc[df['paper_id'] == pid, 'conclusion'] = text\n",
    "\n",
    "# ===== 4. 保存为新文件，避免覆盖原文件 =====\n",
    "output_file = r\"E:\\judita's project\\new data 2\\paper_id_intro_conclusion_enriched_filled.csv\"\n",
    "df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ Filling complete, saved to:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1be3f6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Total records (rows): 5817\n",
      "🧩 Number of fields (columns): 12\n",
      "📋 List of field names:\n",
      "['paper_id', 'section_count', 'introduction', 'conclusion', 'rate0', 'rate1', 'rate2', 'avg_score', 'decision', 'title', 'abstract', 'pdf_link']\n",
      "\n",
      "🔍 Null/Empty String Count per Column:\n",
      "✅ paper_id: No null values\n",
      "✅ section_count: No null values\n",
      "✅ introduction: No null values\n",
      "✅ conclusion: No null values\n",
      "✅ rate0: No null values\n",
      "✅ rate1: No null values\n",
      "✅ rate2: No null values\n",
      "✅ avg_score: No null values\n",
      "✅ decision: No null values\n",
      "✅ title: No null values\n",
      "✅ abstract: No null values\n",
      "✅ pdf_link: No null values\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ✅ Step 1: Modify your file path\n",
    "# Change to your own file path\n",
    "csv_path = r\"E:\\judita's project\\new data 2\\paper_id_intro_conclusion_enriched_filled.csv\"\n",
    "\n",
    "# ✅ Step 2: Read the CSV (handle bad lines / compatible with common encodings)\n",
    "try:\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8', on_bad_lines='skip')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(csv_path, encoding='latin1', on_bad_lines='skip')\n",
    "\n",
    "# ✅ Step 3: Output the total record count and column names\n",
    "print(f\"📊 Total records (rows): {len(df)}\")\n",
    "print(f\"🧩 Number of fields (columns): {df.shape[1]}\")\n",
    "print(\"📋 List of field names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# ✅ Step 4: Count null values / empty strings for each field\n",
    "print(\"\\n🔍 Null/Empty String Count per Column:\")\n",
    "for col in df.columns:\n",
    "    # Null or empty strings (including whitespace-only)\n",
    "    mask = df[col].isna() | (df[col].astype(str).str.strip() == \"\")\n",
    "    count = mask.sum()\n",
    "    if count > 0:\n",
    "        print(f\"⚠️ {col}: {count} null/empty values\")\n",
    "    else:\n",
    "        print(f\"✅ {col}: No null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29a883ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Concatenation complete and saved to: E:\\judita's project\\new data 2\\paper_id_intro_conclusion_combined.csv\n",
      "📦 Fields added: ['title+abstract', 'title+abstract+introduction', 'title+abstract+introduction+conclusion', 'title+abstract+conclusion', 'title+introduction+conclusion']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ✅ Step 1: 读取已清洗的数据集（修改路径为你的）\n",
    "file_path = r\"E:\\judita's project\\new data 2\\paper_id_intro_conclusion_enriched_filled.csv\"\n",
    "df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "\n",
    "# ✅ Step 2: 定义拼接函数（防止空值错误）\n",
    "def safe_concat(prefix, text):\n",
    "    text = str(text).strip()\n",
    "    return f\"{prefix}{text}\" if text else \"\"\n",
    "\n",
    "# ✅ Step 3: 创建组合字段\n",
    "df[\"title+abstract\"] = df.apply(lambda row:\n",
    "    safe_concat(\"title: \", row[\"title\"]) + \" // \" +\n",
    "    safe_concat(\"abstract: \", row[\"abstract\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df[\"title+abstract+introduction\"] = df.apply(lambda row:\n",
    "    safe_concat(\"title: \", row[\"title\"]) + \" // \" +\n",
    "    safe_concat(\"abstract: \", row[\"abstract\"]) + \" // \" +\n",
    "    safe_concat(\"intro: \", row[\"introduction\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df[\"title+abstract+introduction+conclusion\"] = df.apply(lambda row:\n",
    "    safe_concat(\"title: \", row[\"title\"]) + \" // \" +\n",
    "    safe_concat(\"abstract: \", row[\"abstract\"]) + \" // \" +\n",
    "    safe_concat(\"intro: \", row[\"introduction\"]) + \" // \" +\n",
    "    safe_concat(\"concl: \", row[\"conclusion\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df[\"title+abstract+conclusion\"] = df.apply(lambda row:\n",
    "    safe_concat(\"title: \", row[\"title\"]) + \" // \" +\n",
    "    safe_concat(\"abstract: \", row[\"abstract\"]) + \" // \" +\n",
    "    safe_concat(\"concl: \", row[\"conclusion\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df[\"title+introduction+conclusion\"] = df.apply(lambda row:\n",
    "    safe_concat(\"title: \", row[\"title\"]) + \" // \" +\n",
    "    safe_concat(\"intro: \", row[\"introduction\"]) + \" // \" +\n",
    "    safe_concat(\"concl: \", row[\"conclusion\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ✅ Step 4: 保存新的带组合字段的文件\n",
    "output_path = r\"E:\\judita's project\\new data 2\\paper_id_intro_conclusion_combined.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ Concatenation complete and saved to:\", output_path)\n",
    "print(\"📦 Fields added:\", [\n",
    "    \"title+abstract\",\n",
    "    \"title+abstract+introduction\",\n",
    "    \"title+abstract+introduction+conclusion\",\n",
    "    \"title+abstract+conclusion\",\n",
    "    \"title+introduction+conclusion\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f401baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🆔 paper_id: ATp1nW2FuZL\n",
      "\n",
      "📄 Title:\n",
      "neural learning of one-of-many solutions for combinatorial problems in structured output spaces\n",
      "\n",
      "📜 Abstract:\n",
      "Recent research has proposed neural architectures for solving combinatorial problems in structured output spaces. In many such problems, there may exist multiple solutions for a given input, e.g. a partially filled Sudoku puzzle may have many completions satisfying all constraints. Further, we are often interested in finding any \"one\" of the possible solutions, without any preference between them. Existing approaches completely ignore this solution multiplicity. In this paper, we argue that being oblivious to the presence of multiple solutions can severely hamper their training ability. Our contribution is two-fold. First, we formally define the task of learning one-of-many solutions for combinatorial problems in structured output spaces, which is applicable for solving several problems of interest such as N-Queens, and Sudoku. Second, we present a generic learning framework that adapts an existing prediction network for a combinatorial problem to handle solution multiplicity. Our framework uses a selection module, whose goal is to dynamically determine, for every input, the solution that is most effective for training the network parameters in any given learning iteration. We propose an RL based approach to jointly train the selection module with the prediction network. Experiments on three different domains, and using two different prediction networks,  demonstrate that our framework significantly improves the accuracy in our setting, obtaining up to 21 pt gain over the baselines.\n",
      "\n",
      "📘 Introduction:\n",
      "Neural networks have become the de-facto standard for solving perceptual tasks over low level\n",
      "representations, such as pixels in an image or audio signals. Recent research has also explored their\n",
      "application for solving symbolic reasoning tasks, requiring higher level inferences, such as neural\n",
      "theorem proving (Rocktäschel et al., 2015; Evans & Grefenstette, 2018; Minervini et al., 2020), and\n",
      "playing blocks world (Dong et al., 2019). The advantage of neural models for these tasks is that\n",
      "it will create a uniﬁed, end-to-end trainable representation for integrated AI systems that combine\n",
      "perceptual and high level reasoning. Our paper focuses on one such high level reasoning task – solving\n",
      "combinatorial problems in structured output spaces, e.g., solving a Sudoku or N-Queens puzzle.\n",
      "These can be thought of as Constraint Satisfaction problems (CSPs) where the underlying constraints\n",
      "are not explicitly available, and need to be learned from training data. We focus on learning such\n",
      "constraints by a non-autoregressive neural model where variables in the structured output space are\n",
      "decoded simultaneously (and therefore independently). Notably, most of the current state-of-the-art\n",
      "neural models for solving combinatorial problems, e.g. , SATNET (Wang et al., 2019), RRN (Palm\n",
      "et al., 2018), NLM (Dong et al., 2019), work with non autoregressive architectures because of their\n",
      "high efﬁciency of training and inference, since they do not have to decode the solution sequentially.\n",
      "One of the key characteristics of such problems is solution multiplicity – there could be many correct\n",
      "solutions for any given input, even though we may be interested in ﬁnding any one of these solutions.\n",
      "For example, in a game of Sudoku with only 16 digits ﬁlled, there are always multiple correct solutions\n",
      "(McGuire et al., 2012), and obtaining any one of them sufﬁces for solving Sudoku. Unfortunately,\n",
      "existing literature has completely ignored solution multiplicity, resulting in sub-optimally trained\n",
      "∗ Equal contribution. Work done while at IIT Delhi. Current email: deepanshu.jindal@alumni.iitd.ac.in\n",
      "networks. Our preliminary analysis of a state-of-the-art neural Sudoku solver (Palm et al., 2018) 1 ,\n",
      "which trains and tests on instances with single solutions, showed that it achieves a high accuracy of\n",
      "96% on instances with single solution, but the accuracy drops to less than 25%, when tested on inputs\n",
      "that have multiple solutions. Intuitively, the challenge comes from the fact that (a) there could be a\n",
      "very large number of possible solutions for a given input, and (b) the solutions may be highly varied.\n",
      "For example, a 16-givens Sudoku puzzle could have as many as 10,000 solutions, with maximum\n",
      "hamming distance between any two solutions being 61. Hence, we argue that an explicit modeling\n",
      "effort is required to represent this solution multiplicity.\n",
      "As the ﬁrst contribution of our work, we formally deﬁne the novel problem of One-of-Many Learning\n",
      "( 1 oML). It is given training data of the form { ( x i , Y x i ) } , where Y x i denotes a subset of all correct\n",
      "outputs Y x i associated with input x i . The goal of 1 oML is to learn a function f such that, for any\n",
      "input x , f ( x ) = y for some y ∈ Y x . We show that a naïve strategy that uses separate loss terms for\n",
      "each ( x i , y ij ) pair where y ij ∈ Y x i can result in a bad likelihood objective. Next, we introduce a\n",
      "multiplicity aware loss (CC-L OSS ) and demonstrate its limitations for non-autoregressive models\n",
      "on structured output spaces. In response, we present our ﬁrst-cut approach, M IN L OSS , which picks\n",
      "up the single y ij closest to the prediction ˆ y i based on the current parameters of prediction network\n",
      "(base architecture for function f ), and uses it to compute and back-propagate the loss for that training\n",
      "sample x i . Though signiﬁcantly better than naïve training, through a simple example, we demonstrate\n",
      "that M IN L OSS can be sub-optimal in certain scenarios, due to its inability to pick a y ij based on\n",
      "global characteristics of solution space.\n",
      "To alleviate the issues with M IN L OSS , we present two exploration based techniques, I-E XPL R\n",
      "and S ELECT R, that select a y ij in a non-greedy fashion, unlike M IN L OSS . Both techniques are\n",
      "generic in the sense that they can work with any prediction network for the given problem. I-E XPL R\n",
      "relies on the prediction network itself for selecting y ij , whereas S ELECT R is an RL based learning\n",
      "framework which uses a selection module to decide which y ij should be picked for a given input\n",
      "x i , for back-propagating the loss in the next iteration. The S ELECT R’s selection module is trained\n",
      "jointly along with the prediction network using reinforcement learning, thus allowing us to trade-off\n",
      "exploration and exploitation in selecting the optimum y ij by learning a probability distribution over\n",
      "the space of possible y ij ’s for any given input x i .\n",
      "We experiment on three CSPs: N-Queens, Futoshiki, and Sudoku. Our prediction networks for the\n",
      "ﬁrst two problems are constructed using Neural Logic Machines (Dong et al., 2019), and for Sudoku,\n",
      "we use a state-of-the-art neural solver based on Recurrent Relational Networks (Palm et al., 2018). In\n",
      "all three problems, our experiments demonstrate that S ELECT R vastly outperforms naïve baselines\n",
      "by up to 21 pts, underscoring the value of explicitly modeling solution multiplicity. S ELECT R also\n",
      "consistently improves on other multiplicity aware methods, viz. CC-L OSS , M IN L OSS , and I-E XPL R.\n",
      "\n",
      "📕 Conclusion:\n",
      "The main goal of our experiments is to evaluate the four multiplicity aware methods: CC-L OSS ,\n",
      "M IN L OSS , informed exploration (I-E XPL R) and RL based exploration (S ELECT R), when compared\n",
      "to baseline approaches that completely disregard the problem of solution multiplicity. We also\n",
      "wish to assess the performance gap, if any, between queries with a unique solution and those with\n",
      "many possible solutions. To answer these questions, we conduct experiments on three different tasks\n",
      "(N-Queens, Futoshiki & Sudoku), trained over two different prediction networks, as described below. 3\n",
      "4.1\n",
      "D ATASETS AND P REDICTION N ETWORKS\n",
      "N-Queens: Given a query, i.e. , a chess-board of size N × N and a placement of k < N non-attacking\n",
      "queens on it, the task of N Queens is to place the remaining N − k queens, such that no two queens\n",
      "are attacking each other. We train a Neural Logic Machine (NLM) model (Dong et al., 2019) as\n",
      "the prediction network M Θ for solving queries for this task. To model N-Queens within NLM, we\n",
      "represent a query x and the target y as N 2 dimensional Boolean vectors with 1 at locations where a\n",
      "Queen is placed. We use another smaller NLM architecture as the latent model G φ .\n",
      "We train our model on 10–Queens puzzles and test on 11–Queens puzzles, both with 5 placed queens.\n",
      "This size-invariance in training and test is a key strength of NLM architecture, which we exploit\n",
      "in our experiments. To generate the train data, we start with all possible valid 10–Queens board\n",
      "conﬁgurations and randomly mask any 5 queens, and then check for all possible valid completions to\n",
      "3 Further details of software environments, hyperparameters and dataset generation are in the appendix.\n",
      "generate potentially multiple solutions for an input. Test data is also generated similarly. Training\n",
      "and testing on different board sizes ensures that no direct information leaks from test to train. Queries\n",
      "with multiple solutions have 2-6 solutions, so we choose Y x i = Y x i , ∀ x i .\n",
      "Futoshiki: This is a logic puzzle in which we are given a grid of size N × N , and the goal is to\n",
      "ﬁll the grid with digits from { 1 . . . N } such that no digit is repeated in a row or a column. k out of\n",
      "N 2 positions are already ﬁlled in the input query x and the remaining N 2 − k positions need to be\n",
      "ﬁlled. Further, inequality constraints are speciﬁed between some pairs of adjacent grid positions,\n",
      "which need to be honored in the solution. Our prediction network, and latent model use NLM, and\n",
      "the details (described in Appendix) are very similar to that of N–Queens.\n",
      "Similar to N–Queens, we do size-invariant training – we train our models on 5 × 5 puzzles with 14\n",
      "missing digits and test on 6 × 6 puzzles with 20 missing digits. Similar to N–Queens, we generate all\n",
      "possible valid grids and randomly mask out the requisite number of digits to generate train and test\n",
      "data. For both train and test queries we keep up to ﬁve inequality constraints of each type: > and < .\n",
      "Sudoku: We also experiment on Sudoku, which has been used as the task of choice for many recent\n",
      "neural reasoning works (Palm et al., 2018; Wang et al., 2019). We use Relational Recurrent Networks\n",
      "(RRN) (Palm et al., 2018) as the prediction network since it has recently shown state-of-the-art\n",
      "performance on the task. We use a 5 layer CNN as our latent model G φ . Existing Sudoku datasets\n",
      "(Royle, 2014; Park, 2018), do not expose the issues with solution multiplicity. In response, we\n",
      "generate our own dataset by starting with a collection of Sudoku puzzles with unique solutions that\n",
      "have 17 digits ﬁlled. We remove one of the digits, thus generating a puzzle, which is guaranteed to\n",
      "have solution multiplicity. We then randomly add 1 to 18 of the digits back from the solution of the\n",
      "original puzzle, while ensuring that the query continues to have more than 1 solution. This generates\n",
      "our set of multi-solution queries with a uniform distribution of ﬁlled digits from 17 to 34. We mix an\n",
      "equal number of unique solution queries (with same ﬁlled distribution). Because some x i s may have\n",
      "hundreds of solutions, we randomly sample 5 of them from Y x i , i.e., | Y x i | ≤ 5 in the train set. For\n",
      "each dataset, we generate a devset in a manner similar to the test set.\n",
      "B ASELINES AND E VALUATION M ETRIC\n",
      "Our comparison baselines include: (1) Naïve : backpropagating L (Θ) through each solution independently using Equation (1), (2) Unique : computing L (Θ) only over the subset of training examples\n",
      "that have a unique solution\n",
      "and (3) Random : backpropagating L (Θ) through one arbitrarily picked\n",
      "solution y i ∈ Y x i for every x i in the train data\n",
      "and keeping this choice ﬁxed throughout the training.\n",
      "We separately report performance on two mutually exclusive subsets of test data: OS : queries\n",
      "with a unique solution\n",
      "and MS : those with multiple solutions. For all methods, we tune various\n",
      "hyperparameters (and do early stopping) based on the devset performance. Additional parameters for\n",
      "the four multiplicity aware methods include the ratio of OS and MS examples in training. 4 I-E XPL R\n",
      "and S ELECT R also select the pre-training strategy as described in Section 3.5. For all tasks, we\n",
      "consider the output of a prediction network as correct only if it is a valid solution for the underlying\n",
      "CSP. No partial credit is given for guessing parts of the output correctly.\n",
      "4.3\n",
      "R ESULTS AND D ISCUSSION\n",
      "We report the accuracies across all tasks and models in Table 2. For each setting, we report the mean\n",
      "over three random runs (with different seeds), and also the accuracy on the best of these runs selected\n",
      "via the devset (in the parentheses). We ﬁrst observe that Naïve and Random perform signiﬁcantly\n",
      "worse than Unique in all the tasks, not only on MS , but on OS as well. This suggests that, 1 oML\n",
      "models that explicitly handle solution multiplicity, even if by simply discarding multiple solutions,\n",
      "are much better than those that do not recognize it at all.\n",
      "4 Futoshiki and N–Queens training datasets have signiﬁcant OS - MS imbalance (see Table 1), necessitating\n",
      "managing this ratio by undersampling OS . This is similar to standard approach in class imbalance problems.\n",
      "Predictably, all multiplicity aware methods vastly improve upon the performance of naïve baselines,\n",
      "with a dramatic 13-52 pt gains between Unique and S ELECT R on queries with multiple solutions.\n",
      "Comparing M IN L OSS and S ELECT R, we ﬁnd\n",
      "that our RL-based approach outperforms M IN -\n",
      "L OSS consistently, with p-values (computed\n",
      "using McNemar’s test for the best models selected based on validation set) of 1 . 00e − 16 ,\n",
      "0 . 03 , and 1 . 69e − 18 for NQueens, Futoshiki and\n",
      "Sudoku respectively (see Appendix for seed-wise comparisons of gains across tasks). On\n",
      "the other hand, informed exploration technique,\n",
      "I-E XPL R, though improves over M IN L OSS on\n",
      "two out of three tasks, it performs worse than\n",
      "S ELECT R in all the domains. This highlights\n",
      "the value of RL based exploration on top of the\n",
      "greedy target selection of M IN L OSS as well as\n",
      "over the simple exploration of I-E XPL R. We\n",
      "note that this is due to more exploratory power of S ELECT R over I-E XPL R. See Appendix for more\n",
      "discussion and experiments comparing the two exploration techniques.\n",
      "Recall that Sudoku training set has no more than 5 solutions for a query, irrespective of the actual\n",
      "number of solutions – i.e, for many x i , Y x i (cid:40) Y x i . Despite incomplete solution set, signiﬁcant\n",
      "improvement over baselines is obtained, indicating that our formulation handles solution multiplicity\n",
      "even with incomplete information. Furthermore, the large variation in the size of solution set ( |Y x | )\n",
      "in Sudoku allows us to assess its effect on the overall performance. We ﬁnd that all models get worse\n",
      "as |Y x | increases (ﬁg. 3), even though S ELECT R remains the most robust (see Appendix for details).\n",
      "C ONCLUSION AND F UTURE W ORK\n",
      "In this paper, we have deﬁned 1 oML: the task of learning one of many solutions for combinatorial\n",
      "problems in structured output spaces. We have identiﬁed solution multiplicity as an important aspect\n",
      "of the problem, which if not handled properly, may result in sub-optimal models. As a ﬁrst cut\n",
      "solution, we proposed a greedy approach: M IN L OSS formulation. We identiﬁed certain shortcomings\n",
      "with the greedy approach and proposed two exploration based formulations: I-E XPL R and an RL\n",
      "formulation, S ELECT R, which overcomes some of the issues in M IN L OSS by exploring the locally\n",
      "sub-optimal choices for better global optimization.\n",
      "Experiments on three different tasks using two different prediction networks demonstrate the effectiveness of our approach in training robust models under solution multiplicity 5 .\n",
      "It is interesting to note that for traditional CSP solvers, e.g. (Selman et al., 1993; Mahajan et al., 2004),\n",
      "a problem with many solutions will be considered an easy problem, whereas for neural models, such\n",
      "problems appear much harder (Figure 3). As a future work, it will be interesting to combine symbolic\n",
      "CSP solvers with S ELECT R to design a much stronger neuro-symbolic reasoning model.\n",
      "5 All the code and datasets are available at: https://sites.google.com/view/yatinnandwani/1oml\n",
      "A CKNOWLEDGEMENT\n",
      "We thank IIT Delhi HPC facility 6 for computational resources. We thank anonymous reviewers for\n",
      "their insightful comments and suggestions, in particular AnonReviewer4 for suggesting a simple yet\n",
      "effective informed exploration strategy (I-E XPL R). Mausam is supported by grants from Google,\n",
      "Bloomberg, 1MG and Jai Gupta chair fellowship by IIT Delhi. Parag Singla is supported by the\n",
      "DARPA Explainable Artiﬁcial Intelligence (XAI) Program with number N66001-17-2-4032. Both\n",
      "Mausam and Parag Singla are supported by the Visvesvaraya Young Faculty Fellowships by Govt. of\n",
      "India and IBM SUR awards. Any opinions, ﬁndings, conclusions or recommendations expressed in\n",
      "this paper are those of the authors and do not necessarily reﬂect the views or ofﬁcial policies, either\n",
      "expressed or implied, of the funding agencies\n",
      "\n",
      "📎 title+abstract:\n",
      "title: neural learning of one-of-many solutions for combinatorial problems in structured output spaces // abstract: Recent research has proposed neural architectures for solving combinatorial problems in structured output spaces. In many such problems, there may exist multiple solutions for a given input, e.g. a partially filled Sudoku puzzle may have many completions satisfying all constraints. Further, we are often interested in finding any \"one\" of the possible solutions, without any preference between them. Existing approaches completely ignore this solution multiplicity. In this paper, we argue that being oblivious to the presence of multiple solutions can severely hamper their training ability. Our contribution is two-fold. First, we formally define the task of learning one-of-many solutions for combinatorial problems in structured output spaces, which is applicable for solving several problems of interest such as N-Queens, and Sudoku. Second, we present a generic learning framework that adapts an existing prediction network for a combinatorial problem to handle solution multiplicity. Our framework uses a selection module, whose goal is to dynamically determine, for every input, the solution that is most effective for training the network parameters in any given learning iteration. We propose an RL based approach to jointly train the selection module with the prediction network. Experiments on three different domains, and using two different prediction networks,  demonstrate that our framework significantly improves the accuracy in our setting, obtaining up to 21 pt gain over the baselines.\n",
      "\n",
      "📎 title+abstract+introduction:\n",
      "title: neural learning of one-of-many solutions for combinatorial problems in structured output spaces // abstract: Recent research has proposed neural architectures for solving combinatorial problems in structured output spaces. In many such problems, there may exist multiple solutions for a given input, e.g. a partially filled Sudoku puzzle may have many completions satisfying all constraints. Further, we are often interested in finding any \"one\" of the possible solutions, without any preference between them. Existing approaches completely ignore this solution multiplicity. In this paper, we argue that being oblivious to the presence of multiple solutions can severely hamper their training ability. Our contribution is two-fold. First, we formally define the task of learning one-of-many solutions for combinatorial problems in structured output spaces, which is applicable for solving several problems of interest such as N-Queens, and Sudoku. Second, we present a generic learning framework that adapts an existing prediction network for a combinatorial problem to handle solution multiplicity. Our framework uses a selection module, whose goal is to dynamically determine, for every input, the solution that is most effective for training the network parameters in any given learning iteration. We propose an RL based approach to jointly train the selection module with the prediction network. Experiments on three different domains, and using two different prediction networks,  demonstrate that our framework significantly improves the accuracy in our setting, obtaining up to 21 pt gain over the baselines. // intro: Neural networks have become the de-facto standard for solving perceptual tasks over low level\n",
      "representations, such as pixels in an image or audio signals. Recent research has also explored their\n",
      "application for solving symbolic reasoning tasks, requiring higher level inferences, such as neural\n",
      "theorem proving (Rocktäschel et al., 2015; Evans & Grefenstette, 2018; Minervini et al., 2020), and\n",
      "playing blocks world (Dong et al., 2019). The advantage of neural models for these tasks is that\n",
      "it will create a uniﬁed, end-to-end trainable representation for integrated AI systems that combine\n",
      "perceptual and high level reasoning. Our paper focuses on one such high level reasoning task – solving\n",
      "combinatorial problems in structured output spaces, e.g., solving a Sudoku or N-Queens puzzle.\n",
      "These can be thought of as Constraint Satisfaction problems (CSPs) where the underlying constraints\n",
      "are not explicitly available, and need to be learned from training data. We focus on learning such\n",
      "constraints by a non-autoregressive neural model where variables in the structured output space are\n",
      "decoded simultaneously (and therefore independently). Notably, most of the current state-of-the-art\n",
      "neural models for solving combinatorial problems, e.g. , SATNET (Wang et al., 2019), RRN (Palm\n",
      "et al., 2018), NLM (Dong et al., 2019), work with non autoregressive architectures because of their\n",
      "high efﬁciency of training and inference, since they do not have to decode the solution sequentially.\n",
      "One of the key characteristics of such problems is solution multiplicity – there could be many correct\n",
      "solutions for any given input, even though we may be interested in ﬁnding any one of these solutions.\n",
      "For example, in a game of Sudoku with only 16 digits ﬁlled, there are always multiple correct solutions\n",
      "(McGuire et al., 2012), and obtaining any one of them sufﬁces for solving Sudoku. Unfortunately,\n",
      "existing literature has completely ignored solution multiplicity, resulting in sub-optimally trained\n",
      "∗ Equal contribution. Work done while at IIT Delhi. Current email: deepanshu.jindal@alumni.iitd.ac.in\n",
      "networks. Our preliminary analysis of a state-of-the-art neural Sudoku solver (Palm et al., 2018) 1 ,\n",
      "which trains and tests on instances with single solutions, showed that it achieves a high accuracy of\n",
      "96% on instances with single solution, but the accuracy drops to less than 25%, when tested on inputs\n",
      "that have multiple solutions. Intuitively, the challenge comes from the fact that (a) there could be a\n",
      "very large number of possible solutions for a given input, and (b) the solutions may be highly varied.\n",
      "For example, a 16-givens Sudoku puzzle could have as many as 10,000 solutions, with maximum\n",
      "hamming distance between any two solutions being 61. Hence, we argue that an explicit modeling\n",
      "effort is required to represent this solution multiplicity.\n",
      "As the ﬁrst contribution of our work, we formally deﬁne the novel problem of One-of-Many Learning\n",
      "( 1 oML). It is given training data of the form { ( x i , Y x i ) } , where Y x i denotes a subset of all correct\n",
      "outputs Y x i associated with input x i . The goal of 1 oML is to learn a function f such that, for any\n",
      "input x , f ( x ) = y for some y ∈ Y x . We show that a naïve strategy that uses separate loss terms for\n",
      "each ( x i , y ij ) pair where y ij ∈ Y x i can result in a bad likelihood objective. Next, we introduce a\n",
      "multiplicity aware loss (CC-L OSS ) and demonstrate its limitations for non-autoregressive models\n",
      "on structured output spaces. In response, we present our ﬁrst-cut approach, M IN L OSS , which picks\n",
      "up the single y ij closest to the prediction ˆ y i based on the current parameters of prediction network\n",
      "(base architecture for function f ), and uses it to compute and back-propagate the loss for that training\n",
      "sample x i . Though signiﬁcantly better than naïve training, through a simple example, we demonstrate\n",
      "that M IN L OSS can be sub-optimal in certain scenarios, due to its inability to pick a y ij based on\n",
      "global characteristics of solution space.\n",
      "To alleviate the issues with M IN L OSS , we present two exploration based techniques, I-E XPL R\n",
      "and S ELECT R, that select a y ij in a non-greedy fashion, unlike M IN L OSS . Both techniques are\n",
      "generic in the sense that they can work with any prediction network for the given problem. I-E XPL R\n",
      "relies on the prediction network itself for selecting y ij , whereas S ELECT R is an RL based learning\n",
      "framework which uses a selection module to decide which y ij should be picked for a given input\n",
      "x i , for back-propagating the loss in the next iteration. The S ELECT R’s selection module is trained\n",
      "jointly along with the prediction network using reinforcement learning, thus allowing us to trade-off\n",
      "exploration and exploitation in selecting the optimum y ij by learning a probability distribution over\n",
      "the space of possible y ij ’s for any given input x i .\n",
      "We experiment on three CSPs: N-Queens, Futoshiki, and Sudoku. Our prediction networks for the\n",
      "ﬁrst two problems are constructed using Neural Logic Machines (Dong et al., 2019), and for Sudoku,\n",
      "we use a state-of-the-art neural solver based on Recurrent Relational Networks (Palm et al., 2018). In\n",
      "all three problems, our experiments demonstrate that S ELECT R vastly outperforms naïve baselines\n",
      "by up to 21 pts, underscoring the value of explicitly modeling solution multiplicity. S ELECT R also\n",
      "consistently improves on other multiplicity aware methods, viz. CC-L OSS , M IN L OSS , and I-E XPL R.\n",
      "\n",
      "📎 title+abstract+introduction+conclusion:\n",
      "title: neural learning of one-of-many solutions for combinatorial problems in structured output spaces // abstract: Recent research has proposed neural architectures for solving combinatorial problems in structured output spaces. In many such problems, there may exist multiple solutions for a given input, e.g. a partially filled Sudoku puzzle may have many completions satisfying all constraints. Further, we are often interested in finding any \"one\" of the possible solutions, without any preference between them. Existing approaches completely ignore this solution multiplicity. In this paper, we argue that being oblivious to the presence of multiple solutions can severely hamper their training ability. Our contribution is two-fold. First, we formally define the task of learning one-of-many solutions for combinatorial problems in structured output spaces, which is applicable for solving several problems of interest such as N-Queens, and Sudoku. Second, we present a generic learning framework that adapts an existing prediction network for a combinatorial problem to handle solution multiplicity. Our framework uses a selection module, whose goal is to dynamically determine, for every input, the solution that is most effective for training the network parameters in any given learning iteration. We propose an RL based approach to jointly train the selection module with the prediction network. Experiments on three different domains, and using two different prediction networks,  demonstrate that our framework significantly improves the accuracy in our setting, obtaining up to 21 pt gain over the baselines. // intro: Neural networks have become the de-facto standard for solving perceptual tasks over low level\n",
      "representations, such as pixels in an image or audio signals. Recent research has also explored their\n",
      "application for solving symbolic reasoning tasks, requiring higher level inferences, such as neural\n",
      "theorem proving (Rocktäschel et al., 2015; Evans & Grefenstette, 2018; Minervini et al., 2020), and\n",
      "playing blocks world (Dong et al., 2019). The advantage of neural models for these tasks is that\n",
      "it will create a uniﬁed, end-to-end trainable representation for integrated AI systems that combine\n",
      "perceptual and high level reasoning. Our paper focuses on one such high level reasoning task – solving\n",
      "combinatorial problems in structured output spaces, e.g., solving a Sudoku or N-Queens puzzle.\n",
      "These can be thought of as Constraint Satisfaction problems (CSPs) where the underlying constraints\n",
      "are not explicitly available, and need to be learned from training data. We focus on learning such\n",
      "constraints by a non-autoregressive neural model where variables in the structured output space are\n",
      "decoded simultaneously (and therefore independently). Notably, most of the current state-of-the-art\n",
      "neural models for solving combinatorial problems, e.g. , SATNET (Wang et al., 2019), RRN (Palm\n",
      "et al., 2018), NLM (Dong et al., 2019), work with non autoregressive architectures because of their\n",
      "high efﬁciency of training and inference, since they do not have to decode the solution sequentially.\n",
      "One of the key characteristics of such problems is solution multiplicity – there could be many correct\n",
      "solutions for any given input, even though we may be interested in ﬁnding any one of these solutions.\n",
      "For example, in a game of Sudoku with only 16 digits ﬁlled, there are always multiple correct solutions\n",
      "(McGuire et al., 2012), and obtaining any one of them sufﬁces for solving Sudoku. Unfortunately,\n",
      "existing literature has completely ignored solution multiplicity, resulting in sub-optimally trained\n",
      "∗ Equal contribution. Work done while at IIT Delhi. Current email: deepanshu.jindal@alumni.iitd.ac.in\n",
      "networks. Our preliminary analysis of a state-of-the-art neural Sudoku solver (Palm et al., 2018) 1 ,\n",
      "which trains and tests on instances with single solutions, showed that it achieves a high accuracy of\n",
      "96% on instances with single solution, but the accuracy drops to less than 25%, when tested on inputs\n",
      "that have multiple solutions. Intuitively, the challenge comes from the fact that (a) there could be a\n",
      "very large number of possible solutions for a given input, and (b) the solutions may be highly varied.\n",
      "For example, a 16-givens Sudoku puzzle could have as many as 10,000 solutions, with maximum\n",
      "hamming distance between any two solutions being 61. Hence, we argue that an explicit modeling\n",
      "effort is required to represent this solution multiplicity.\n",
      "As the ﬁrst contribution of our work, we formally deﬁne the novel problem of One-of-Many Learning\n",
      "( 1 oML). It is given training data of the form { ( x i , Y x i ) } , where Y x i denotes a subset of all correct\n",
      "outputs Y x i associated with input x i . The goal of 1 oML is to learn a function f such that, for any\n",
      "input x , f ( x ) = y for some y ∈ Y x . We show that a naïve strategy that uses separate loss terms for\n",
      "each ( x i , y ij ) pair where y ij ∈ Y x i can result in a bad likelihood objective. Next, we introduce a\n",
      "multiplicity aware loss (CC-L OSS ) and demonstrate its limitations for non-autoregressive models\n",
      "on structured output spaces. In response, we present our ﬁrst-cut approach, M IN L OSS , which picks\n",
      "up the single y ij closest to the prediction ˆ y i based on the current parameters of prediction network\n",
      "(base architecture for function f ), and uses it to compute and back-propagate the loss for that training\n",
      "sample x i . Though signiﬁcantly better than naïve training, through a simple example, we demonstrate\n",
      "that M IN L OSS can be sub-optimal in certain scenarios, due to its inability to pick a y ij based on\n",
      "global characteristics of solution space.\n",
      "To alleviate the issues with M IN L OSS , we present two exploration based techniques, I-E XPL R\n",
      "and S ELECT R, that select a y ij in a non-greedy fashion, unlike M IN L OSS . Both techniques are\n",
      "generic in the sense that they can work with any prediction network for the given problem. I-E XPL R\n",
      "relies on the prediction network itself for selecting y ij , whereas S ELECT R is an RL based learning\n",
      "framework which uses a selection module to decide which y ij should be picked for a given input\n",
      "x i , for back-propagating the loss in the next iteration. The S ELECT R’s selection module is trained\n",
      "jointly along with the prediction network using reinforcement learning, thus allowing us to trade-off\n",
      "exploration and exploitation in selecting the optimum y ij by learning a probability distribution over\n",
      "the space of possible y ij ’s for any given input x i .\n",
      "We experiment on three CSPs: N-Queens, Futoshiki, and Sudoku. Our prediction networks for the\n",
      "ﬁrst two problems are constructed using Neural Logic Machines (Dong et al., 2019), and for Sudoku,\n",
      "we use a state-of-the-art neural solver based on Recurrent Relational Networks (Palm et al., 2018). In\n",
      "all three problems, our experiments demonstrate that S ELECT R vastly outperforms naïve baselines\n",
      "by up to 21 pts, underscoring the value of explicitly modeling solution multiplicity. S ELECT R also\n",
      "consistently improves on other multiplicity aware methods, viz. CC-L OSS , M IN L OSS , and I-E XPL R. // concl: The main goal of our experiments is to evaluate the four multiplicity aware methods: CC-L OSS ,\n",
      "M IN L OSS , informed exploration (I-E XPL R) and RL based exploration (S ELECT R), when compared\n",
      "to baseline approaches that completely disregard the problem of solution multiplicity. We also\n",
      "wish to assess the performance gap, if any, between queries with a unique solution and those with\n",
      "many possible solutions. To answer these questions, we conduct experiments on three different tasks\n",
      "(N-Queens, Futoshiki & Sudoku), trained over two different prediction networks, as described below. 3\n",
      "4.1\n",
      "D ATASETS AND P REDICTION N ETWORKS\n",
      "N-Queens: Given a query, i.e. , a chess-board of size N × N and a placement of k < N non-attacking\n",
      "queens on it, the task of N Queens is to place the remaining N − k queens, such that no two queens\n",
      "are attacking each other. We train a Neural Logic Machine (NLM) model (Dong et al., 2019) as\n",
      "the prediction network M Θ for solving queries for this task. To model N-Queens within NLM, we\n",
      "represent a query x and the target y as N 2 dimensional Boolean vectors with 1 at locations where a\n",
      "Queen is placed. We use another smaller NLM architecture as the latent model G φ .\n",
      "We train our model on 10–Queens puzzles and test on 11–Queens puzzles, both with 5 placed queens.\n",
      "This size-invariance in training and test is a key strength of NLM architecture, which we exploit\n",
      "in our experiments. To generate the train data, we start with all possible valid 10–Queens board\n",
      "conﬁgurations and randomly mask any 5 queens, and then check for all possible valid completions to\n",
      "3 Further details of software environments, hyperparameters and dataset generation are in the appendix.\n",
      "generate potentially multiple solutions for an input. Test data is also generated similarly. Training\n",
      "and testing on different board sizes ensures that no direct information leaks from test to train. Queries\n",
      "with multiple solutions have 2-6 solutions, so we choose Y x i = Y x i , ∀ x i .\n",
      "Futoshiki: This is a logic puzzle in which we are given a grid of size N × N , and the goal is to\n",
      "ﬁll the grid with digits from { 1 . . . N } such that no digit is repeated in a row or a column. k out of\n",
      "N 2 positions are already ﬁlled in the input query x and the remaining N 2 − k positions need to be\n",
      "ﬁlled. Further, inequality constraints are speciﬁed between some pairs of adjacent grid positions,\n",
      "which need to be honored in the solution. Our prediction network, and latent model use NLM, and\n",
      "the details (described in Appendix) are very similar to that of N–Queens.\n",
      "Similar to N–Queens, we do size-invariant training – we train our models on 5 × 5 puzzles with 14\n",
      "missing digits and test on 6 × 6 puzzles with 20 missing digits. Similar to N–Queens, we generate all\n",
      "possible valid grids and randomly mask out the requisite number of digits to generate train and test\n",
      "data. For both train and test queries we keep up to ﬁve inequality constraints of each type: > and < .\n",
      "Sudoku: We also experiment on Sudoku, which has been used as the task of choice for many recent\n",
      "neural reasoning works (Palm et al., 2018; Wang et al., 2019). We use Relational Recurrent Networks\n",
      "(RRN) (Palm et al., 2018) as the prediction network since it has recently shown state-of-the-art\n",
      "performance on the task. We use a 5 layer CNN as our latent model G φ . Existing Sudoku datasets\n",
      "(Royle, 2014; Park, 2018), do not expose the issues with solution multiplicity. In response, we\n",
      "generate our own dataset by starting with a collection of Sudoku puzzles with unique solutions that\n",
      "have 17 digits ﬁlled. We remove one of the digits, thus generating a puzzle, which is guaranteed to\n",
      "have solution multiplicity. We then randomly add 1 to 18 of the digits back from the solution of the\n",
      "original puzzle, while ensuring that the query continues to have more than 1 solution. This generates\n",
      "our set of multi-solution queries with a uniform distribution of ﬁlled digits from 17 to 34. We mix an\n",
      "equal number of unique solution queries (with same ﬁlled distribution). Because some x i s may have\n",
      "hundreds of solutions, we randomly sample 5 of them from Y x i , i.e., | Y x i | ≤ 5 in the train set. For\n",
      "each dataset, we generate a devset in a manner similar to the test set.\n",
      "B ASELINES AND E VALUATION M ETRIC\n",
      "Our comparison baselines include: (1) Naïve : backpropagating L (Θ) through each solution independently using Equation (1), (2) Unique : computing L (Θ) only over the subset of training examples\n",
      "that have a unique solution\n",
      "and (3) Random : backpropagating L (Θ) through one arbitrarily picked\n",
      "solution y i ∈ Y x i for every x i in the train data\n",
      "and keeping this choice ﬁxed throughout the training.\n",
      "We separately report performance on two mutually exclusive subsets of test data: OS : queries\n",
      "with a unique solution\n",
      "and MS : those with multiple solutions. For all methods, we tune various\n",
      "hyperparameters (and do early stopping) based on the devset performance. Additional parameters for\n",
      "the four multiplicity aware methods include the ratio of OS and MS examples in training. 4 I-E XPL R\n",
      "and S ELECT R also select the pre-training strategy as described in Section 3.5. For all tasks, we\n",
      "consider the output of a prediction network as correct only if it is a valid solution for the underlying\n",
      "CSP. No partial credit is given for guessing parts of the output correctly.\n",
      "4.3\n",
      "R ESULTS AND D ISCUSSION\n",
      "We report the accuracies across all tasks and models in Table 2. For each setting, we report the mean\n",
      "over three random runs (with different seeds), and also the accuracy on the best of these runs selected\n",
      "via the devset (in the parentheses). We ﬁrst observe that Naïve and Random perform signiﬁcantly\n",
      "worse than Unique in all the tasks, not only on MS , but on OS as well. This suggests that, 1 oML\n",
      "models that explicitly handle solution multiplicity, even if by simply discarding multiple solutions,\n",
      "are much better than those that do not recognize it at all.\n",
      "4 Futoshiki and N–Queens training datasets have signiﬁcant OS - MS imbalance (see Table 1), necessitating\n",
      "managing this ratio by undersampling OS . This is similar to standard approach in class imbalance problems.\n",
      "Predictably, all multiplicity aware methods vastly improve upon the performance of naïve baselines,\n",
      "with a dramatic 13-52 pt gains between Unique and S ELECT R on queries with multiple solutions.\n",
      "Comparing M IN L OSS and S ELECT R, we ﬁnd\n",
      "that our RL-based approach outperforms M IN -\n",
      "L OSS consistently, with p-values (computed\n",
      "using McNemar’s test for the best models selected based on validation set) of 1 . 00e − 16 ,\n",
      "0 . 03 , and 1 . 69e − 18 for NQueens, Futoshiki and\n",
      "Sudoku respectively (see Appendix for seed-wise comparisons of gains across tasks). On\n",
      "the other hand, informed exploration technique,\n",
      "I-E XPL R, though improves over M IN L OSS on\n",
      "two out of three tasks, it performs worse than\n",
      "S ELECT R in all the domains. This highlights\n",
      "the value of RL based exploration on top of the\n",
      "greedy target selection of M IN L OSS as well as\n",
      "over the simple exploration of I-E XPL R. We\n",
      "note that this is due to more exploratory power of S ELECT R over I-E XPL R. See Appendix for more\n",
      "discussion and experiments comparing the two exploration techniques.\n",
      "Recall that Sudoku training set has no more than 5 solutions for a query, irrespective of the actual\n",
      "number of solutions – i.e, for many x i , Y x i (cid:40) Y x i . Despite incomplete solution set, signiﬁcant\n",
      "improvement over baselines is obtained, indicating that our formulation handles solution multiplicity\n",
      "even with incomplete information. Furthermore, the large variation in the size of solution set ( |Y x | )\n",
      "in Sudoku allows us to assess its effect on the overall performance. We ﬁnd that all models get worse\n",
      "as |Y x | increases (ﬁg. 3), even though S ELECT R remains the most robust (see Appendix for details).\n",
      "C ONCLUSION AND F UTURE W ORK\n",
      "In this paper, we have deﬁned 1 oML: the task of learning one of many solutions for combinatorial\n",
      "problems in structured output spaces. We have identiﬁed solution multiplicity as an important aspect\n",
      "of the problem, which if not handled properly, may result in sub-optimal models. As a ﬁrst cut\n",
      "solution, we proposed a greedy approach: M IN L OSS formulation. We identiﬁed certain shortcomings\n",
      "with the greedy approach and proposed two exploration based formulations: I-E XPL R and an RL\n",
      "formulation, S ELECT R, which overcomes some of the issues in M IN L OSS by exploring the locally\n",
      "sub-optimal choices for better global optimization.\n",
      "Experiments on three different tasks using two different prediction networks demonstrate the effectiveness of our approach in training robust models under solution multiplicity 5 .\n",
      "It is interesting to note that for traditional CSP solvers, e.g. (Selman et al., 1993; Mahajan et al., 2004),\n",
      "a problem with many solutions will be considered an easy problem, whereas for neural models, such\n",
      "problems appear much harder (Figure 3). As a future work, it will be interesting to combine symbolic\n",
      "CSP solvers with S ELECT R to design a much stronger neuro-symbolic reasoning model.\n",
      "5 All the code and datasets are available at: https://sites.google.com/view/yatinnandwani/1oml\n",
      "A CKNOWLEDGEMENT\n",
      "We thank IIT Delhi HPC facility 6 for computational resources. We thank anonymous reviewers for\n",
      "their insightful comments and suggestions, in particular AnonReviewer4 for suggesting a simple yet\n",
      "effective informed exploration strategy (I-E XPL R). Mausam is supported by grants from Google,\n",
      "Bloomberg, 1MG and Jai Gupta chair fellowship by IIT Delhi. Parag Singla is supported by the\n",
      "DARPA Explainable Artiﬁcial Intelligence (XAI) Program with number N66001-17-2-4032. Both\n",
      "Mausam and Parag Singla are supported by the Visvesvaraya Young Faculty Fellowships by Govt. of\n",
      "India and IBM SUR awards. Any opinions, ﬁndings, conclusions or recommendations expressed in\n",
      "this paper are those of the authors and do not necessarily reﬂect the views or ofﬁcial policies, either\n",
      "expressed or implied, of the funding agencies\n",
      "\n",
      "📎 title+abstract+conclusion:\n",
      "title: neural learning of one-of-many solutions for combinatorial problems in structured output spaces // abstract: Recent research has proposed neural architectures for solving combinatorial problems in structured output spaces. In many such problems, there may exist multiple solutions for a given input, e.g. a partially filled Sudoku puzzle may have many completions satisfying all constraints. Further, we are often interested in finding any \"one\" of the possible solutions, without any preference between them. Existing approaches completely ignore this solution multiplicity. In this paper, we argue that being oblivious to the presence of multiple solutions can severely hamper their training ability. Our contribution is two-fold. First, we formally define the task of learning one-of-many solutions for combinatorial problems in structured output spaces, which is applicable for solving several problems of interest such as N-Queens, and Sudoku. Second, we present a generic learning framework that adapts an existing prediction network for a combinatorial problem to handle solution multiplicity. Our framework uses a selection module, whose goal is to dynamically determine, for every input, the solution that is most effective for training the network parameters in any given learning iteration. We propose an RL based approach to jointly train the selection module with the prediction network. Experiments on three different domains, and using two different prediction networks,  demonstrate that our framework significantly improves the accuracy in our setting, obtaining up to 21 pt gain over the baselines. // concl: The main goal of our experiments is to evaluate the four multiplicity aware methods: CC-L OSS ,\n",
      "M IN L OSS , informed exploration (I-E XPL R) and RL based exploration (S ELECT R), when compared\n",
      "to baseline approaches that completely disregard the problem of solution multiplicity. We also\n",
      "wish to assess the performance gap, if any, between queries with a unique solution and those with\n",
      "many possible solutions. To answer these questions, we conduct experiments on three different tasks\n",
      "(N-Queens, Futoshiki & Sudoku), trained over two different prediction networks, as described below. 3\n",
      "4.1\n",
      "D ATASETS AND P REDICTION N ETWORKS\n",
      "N-Queens: Given a query, i.e. , a chess-board of size N × N and a placement of k < N non-attacking\n",
      "queens on it, the task of N Queens is to place the remaining N − k queens, such that no two queens\n",
      "are attacking each other. We train a Neural Logic Machine (NLM) model (Dong et al., 2019) as\n",
      "the prediction network M Θ for solving queries for this task. To model N-Queens within NLM, we\n",
      "represent a query x and the target y as N 2 dimensional Boolean vectors with 1 at locations where a\n",
      "Queen is placed. We use another smaller NLM architecture as the latent model G φ .\n",
      "We train our model on 10–Queens puzzles and test on 11–Queens puzzles, both with 5 placed queens.\n",
      "This size-invariance in training and test is a key strength of NLM architecture, which we exploit\n",
      "in our experiments. To generate the train data, we start with all possible valid 10–Queens board\n",
      "conﬁgurations and randomly mask any 5 queens, and then check for all possible valid completions to\n",
      "3 Further details of software environments, hyperparameters and dataset generation are in the appendix.\n",
      "generate potentially multiple solutions for an input. Test data is also generated similarly. Training\n",
      "and testing on different board sizes ensures that no direct information leaks from test to train. Queries\n",
      "with multiple solutions have 2-6 solutions, so we choose Y x i = Y x i , ∀ x i .\n",
      "Futoshiki: This is a logic puzzle in which we are given a grid of size N × N , and the goal is to\n",
      "ﬁll the grid with digits from { 1 . . . N } such that no digit is repeated in a row or a column. k out of\n",
      "N 2 positions are already ﬁlled in the input query x and the remaining N 2 − k positions need to be\n",
      "ﬁlled. Further, inequality constraints are speciﬁed between some pairs of adjacent grid positions,\n",
      "which need to be honored in the solution. Our prediction network, and latent model use NLM, and\n",
      "the details (described in Appendix) are very similar to that of N–Queens.\n",
      "Similar to N–Queens, we do size-invariant training – we train our models on 5 × 5 puzzles with 14\n",
      "missing digits and test on 6 × 6 puzzles with 20 missing digits. Similar to N–Queens, we generate all\n",
      "possible valid grids and randomly mask out the requisite number of digits to generate train and test\n",
      "data. For both train and test queries we keep up to ﬁve inequality constraints of each type: > and < .\n",
      "Sudoku: We also experiment on Sudoku, which has been used as the task of choice for many recent\n",
      "neural reasoning works (Palm et al., 2018; Wang et al., 2019). We use Relational Recurrent Networks\n",
      "(RRN) (Palm et al., 2018) as the prediction network since it has recently shown state-of-the-art\n",
      "performance on the task. We use a 5 layer CNN as our latent model G φ . Existing Sudoku datasets\n",
      "(Royle, 2014; Park, 2018), do not expose the issues with solution multiplicity. In response, we\n",
      "generate our own dataset by starting with a collection of Sudoku puzzles with unique solutions that\n",
      "have 17 digits ﬁlled. We remove one of the digits, thus generating a puzzle, which is guaranteed to\n",
      "have solution multiplicity. We then randomly add 1 to 18 of the digits back from the solution of the\n",
      "original puzzle, while ensuring that the query continues to have more than 1 solution. This generates\n",
      "our set of multi-solution queries with a uniform distribution of ﬁlled digits from 17 to 34. We mix an\n",
      "equal number of unique solution queries (with same ﬁlled distribution). Because some x i s may have\n",
      "hundreds of solutions, we randomly sample 5 of them from Y x i , i.e., | Y x i | ≤ 5 in the train set. For\n",
      "each dataset, we generate a devset in a manner similar to the test set.\n",
      "B ASELINES AND E VALUATION M ETRIC\n",
      "Our comparison baselines include: (1) Naïve : backpropagating L (Θ) through each solution independently using Equation (1), (2) Unique : computing L (Θ) only over the subset of training examples\n",
      "that have a unique solution\n",
      "and (3) Random : backpropagating L (Θ) through one arbitrarily picked\n",
      "solution y i ∈ Y x i for every x i in the train data\n",
      "and keeping this choice ﬁxed throughout the training.\n",
      "We separately report performance on two mutually exclusive subsets of test data: OS : queries\n",
      "with a unique solution\n",
      "and MS : those with multiple solutions. For all methods, we tune various\n",
      "hyperparameters (and do early stopping) based on the devset performance. Additional parameters for\n",
      "the four multiplicity aware methods include the ratio of OS and MS examples in training. 4 I-E XPL R\n",
      "and S ELECT R also select the pre-training strategy as described in Section 3.5. For all tasks, we\n",
      "consider the output of a prediction network as correct only if it is a valid solution for the underlying\n",
      "CSP. No partial credit is given for guessing parts of the output correctly.\n",
      "4.3\n",
      "R ESULTS AND D ISCUSSION\n",
      "We report the accuracies across all tasks and models in Table 2. For each setting, we report the mean\n",
      "over three random runs (with different seeds), and also the accuracy on the best of these runs selected\n",
      "via the devset (in the parentheses). We ﬁrst observe that Naïve and Random perform signiﬁcantly\n",
      "worse than Unique in all the tasks, not only on MS , but on OS as well. This suggests that, 1 oML\n",
      "models that explicitly handle solution multiplicity, even if by simply discarding multiple solutions,\n",
      "are much better than those that do not recognize it at all.\n",
      "4 Futoshiki and N–Queens training datasets have signiﬁcant OS - MS imbalance (see Table 1), necessitating\n",
      "managing this ratio by undersampling OS . This is similar to standard approach in class imbalance problems.\n",
      "Predictably, all multiplicity aware methods vastly improve upon the performance of naïve baselines,\n",
      "with a dramatic 13-52 pt gains between Unique and S ELECT R on queries with multiple solutions.\n",
      "Comparing M IN L OSS and S ELECT R, we ﬁnd\n",
      "that our RL-based approach outperforms M IN -\n",
      "L OSS consistently, with p-values (computed\n",
      "using McNemar’s test for the best models selected based on validation set) of 1 . 00e − 16 ,\n",
      "0 . 03 , and 1 . 69e − 18 for NQueens, Futoshiki and\n",
      "Sudoku respectively (see Appendix for seed-wise comparisons of gains across tasks). On\n",
      "the other hand, informed exploration technique,\n",
      "I-E XPL R, though improves over M IN L OSS on\n",
      "two out of three tasks, it performs worse than\n",
      "S ELECT R in all the domains. This highlights\n",
      "the value of RL based exploration on top of the\n",
      "greedy target selection of M IN L OSS as well as\n",
      "over the simple exploration of I-E XPL R. We\n",
      "note that this is due to more exploratory power of S ELECT R over I-E XPL R. See Appendix for more\n",
      "discussion and experiments comparing the two exploration techniques.\n",
      "Recall that Sudoku training set has no more than 5 solutions for a query, irrespective of the actual\n",
      "number of solutions – i.e, for many x i , Y x i (cid:40) Y x i . Despite incomplete solution set, signiﬁcant\n",
      "improvement over baselines is obtained, indicating that our formulation handles solution multiplicity\n",
      "even with incomplete information. Furthermore, the large variation in the size of solution set ( |Y x | )\n",
      "in Sudoku allows us to assess its effect on the overall performance. We ﬁnd that all models get worse\n",
      "as |Y x | increases (ﬁg. 3), even though S ELECT R remains the most robust (see Appendix for details).\n",
      "C ONCLUSION AND F UTURE W ORK\n",
      "In this paper, we have deﬁned 1 oML: the task of learning one of many solutions for combinatorial\n",
      "problems in structured output spaces. We have identiﬁed solution multiplicity as an important aspect\n",
      "of the problem, which if not handled properly, may result in sub-optimal models. As a ﬁrst cut\n",
      "solution, we proposed a greedy approach: M IN L OSS formulation. We identiﬁed certain shortcomings\n",
      "with the greedy approach and proposed two exploration based formulations: I-E XPL R and an RL\n",
      "formulation, S ELECT R, which overcomes some of the issues in M IN L OSS by exploring the locally\n",
      "sub-optimal choices for better global optimization.\n",
      "Experiments on three different tasks using two different prediction networks demonstrate the effectiveness of our approach in training robust models under solution multiplicity 5 .\n",
      "It is interesting to note that for traditional CSP solvers, e.g. (Selman et al., 1993; Mahajan et al., 2004),\n",
      "a problem with many solutions will be considered an easy problem, whereas for neural models, such\n",
      "problems appear much harder (Figure 3). As a future work, it will be interesting to combine symbolic\n",
      "CSP solvers with S ELECT R to design a much stronger neuro-symbolic reasoning model.\n",
      "5 All the code and datasets are available at: https://sites.google.com/view/yatinnandwani/1oml\n",
      "A CKNOWLEDGEMENT\n",
      "We thank IIT Delhi HPC facility 6 for computational resources. We thank anonymous reviewers for\n",
      "their insightful comments and suggestions, in particular AnonReviewer4 for suggesting a simple yet\n",
      "effective informed exploration strategy (I-E XPL R). Mausam is supported by grants from Google,\n",
      "Bloomberg, 1MG and Jai Gupta chair fellowship by IIT Delhi. Parag Singla is supported by the\n",
      "DARPA Explainable Artiﬁcial Intelligence (XAI) Program with number N66001-17-2-4032. Both\n",
      "Mausam and Parag Singla are supported by the Visvesvaraya Young Faculty Fellowships by Govt. of\n",
      "India and IBM SUR awards. Any opinions, ﬁndings, conclusions or recommendations expressed in\n",
      "this paper are those of the authors and do not necessarily reﬂect the views or ofﬁcial policies, either\n",
      "expressed or implied, of the funding agencies\n",
      "\n",
      "📎 title+introduction+conclusion:\n",
      "title: neural learning of one-of-many solutions for combinatorial problems in structured output spaces // intro: Neural networks have become the de-facto standard for solving perceptual tasks over low level\n",
      "representations, such as pixels in an image or audio signals. Recent research has also explored their\n",
      "application for solving symbolic reasoning tasks, requiring higher level inferences, such as neural\n",
      "theorem proving (Rocktäschel et al., 2015; Evans & Grefenstette, 2018; Minervini et al., 2020), and\n",
      "playing blocks world (Dong et al., 2019). The advantage of neural models for these tasks is that\n",
      "it will create a uniﬁed, end-to-end trainable representation for integrated AI systems that combine\n",
      "perceptual and high level reasoning. Our paper focuses on one such high level reasoning task – solving\n",
      "combinatorial problems in structured output spaces, e.g., solving a Sudoku or N-Queens puzzle.\n",
      "These can be thought of as Constraint Satisfaction problems (CSPs) where the underlying constraints\n",
      "are not explicitly available, and need to be learned from training data. We focus on learning such\n",
      "constraints by a non-autoregressive neural model where variables in the structured output space are\n",
      "decoded simultaneously (and therefore independently). Notably, most of the current state-of-the-art\n",
      "neural models for solving combinatorial problems, e.g. , SATNET (Wang et al., 2019), RRN (Palm\n",
      "et al., 2018), NLM (Dong et al., 2019), work with non autoregressive architectures because of their\n",
      "high efﬁciency of training and inference, since they do not have to decode the solution sequentially.\n",
      "One of the key characteristics of such problems is solution multiplicity – there could be many correct\n",
      "solutions for any given input, even though we may be interested in ﬁnding any one of these solutions.\n",
      "For example, in a game of Sudoku with only 16 digits ﬁlled, there are always multiple correct solutions\n",
      "(McGuire et al., 2012), and obtaining any one of them sufﬁces for solving Sudoku. Unfortunately,\n",
      "existing literature has completely ignored solution multiplicity, resulting in sub-optimally trained\n",
      "∗ Equal contribution. Work done while at IIT Delhi. Current email: deepanshu.jindal@alumni.iitd.ac.in\n",
      "networks. Our preliminary analysis of a state-of-the-art neural Sudoku solver (Palm et al., 2018) 1 ,\n",
      "which trains and tests on instances with single solutions, showed that it achieves a high accuracy of\n",
      "96% on instances with single solution, but the accuracy drops to less than 25%, when tested on inputs\n",
      "that have multiple solutions. Intuitively, the challenge comes from the fact that (a) there could be a\n",
      "very large number of possible solutions for a given input, and (b) the solutions may be highly varied.\n",
      "For example, a 16-givens Sudoku puzzle could have as many as 10,000 solutions, with maximum\n",
      "hamming distance between any two solutions being 61. Hence, we argue that an explicit modeling\n",
      "effort is required to represent this solution multiplicity.\n",
      "As the ﬁrst contribution of our work, we formally deﬁne the novel problem of One-of-Many Learning\n",
      "( 1 oML). It is given training data of the form { ( x i , Y x i ) } , where Y x i denotes a subset of all correct\n",
      "outputs Y x i associated with input x i . The goal of 1 oML is to learn a function f such that, for any\n",
      "input x , f ( x ) = y for some y ∈ Y x . We show that a naïve strategy that uses separate loss terms for\n",
      "each ( x i , y ij ) pair where y ij ∈ Y x i can result in a bad likelihood objective. Next, we introduce a\n",
      "multiplicity aware loss (CC-L OSS ) and demonstrate its limitations for non-autoregressive models\n",
      "on structured output spaces. In response, we present our ﬁrst-cut approach, M IN L OSS , which picks\n",
      "up the single y ij closest to the prediction ˆ y i based on the current parameters of prediction network\n",
      "(base architecture for function f ), and uses it to compute and back-propagate the loss for that training\n",
      "sample x i . Though signiﬁcantly better than naïve training, through a simple example, we demonstrate\n",
      "that M IN L OSS can be sub-optimal in certain scenarios, due to its inability to pick a y ij based on\n",
      "global characteristics of solution space.\n",
      "To alleviate the issues with M IN L OSS , we present two exploration based techniques, I-E XPL R\n",
      "and S ELECT R, that select a y ij in a non-greedy fashion, unlike M IN L OSS . Both techniques are\n",
      "generic in the sense that they can work with any prediction network for the given problem. I-E XPL R\n",
      "relies on the prediction network itself for selecting y ij , whereas S ELECT R is an RL based learning\n",
      "framework which uses a selection module to decide which y ij should be picked for a given input\n",
      "x i , for back-propagating the loss in the next iteration. The S ELECT R’s selection module is trained\n",
      "jointly along with the prediction network using reinforcement learning, thus allowing us to trade-off\n",
      "exploration and exploitation in selecting the optimum y ij by learning a probability distribution over\n",
      "the space of possible y ij ’s for any given input x i .\n",
      "We experiment on three CSPs: N-Queens, Futoshiki, and Sudoku. Our prediction networks for the\n",
      "ﬁrst two problems are constructed using Neural Logic Machines (Dong et al., 2019), and for Sudoku,\n",
      "we use a state-of-the-art neural solver based on Recurrent Relational Networks (Palm et al., 2018). In\n",
      "all three problems, our experiments demonstrate that S ELECT R vastly outperforms naïve baselines\n",
      "by up to 21 pts, underscoring the value of explicitly modeling solution multiplicity. S ELECT R also\n",
      "consistently improves on other multiplicity aware methods, viz. CC-L OSS , M IN L OSS , and I-E XPL R. // concl: The main goal of our experiments is to evaluate the four multiplicity aware methods: CC-L OSS ,\n",
      "M IN L OSS , informed exploration (I-E XPL R) and RL based exploration (S ELECT R), when compared\n",
      "to baseline approaches that completely disregard the problem of solution multiplicity. We also\n",
      "wish to assess the performance gap, if any, between queries with a unique solution and those with\n",
      "many possible solutions. To answer these questions, we conduct experiments on three different tasks\n",
      "(N-Queens, Futoshiki & Sudoku), trained over two different prediction networks, as described below. 3\n",
      "4.1\n",
      "D ATASETS AND P REDICTION N ETWORKS\n",
      "N-Queens: Given a query, i.e. , a chess-board of size N × N and a placement of k < N non-attacking\n",
      "queens on it, the task of N Queens is to place the remaining N − k queens, such that no two queens\n",
      "are attacking each other. We train a Neural Logic Machine (NLM) model (Dong et al., 2019) as\n",
      "the prediction network M Θ for solving queries for this task. To model N-Queens within NLM, we\n",
      "represent a query x and the target y as N 2 dimensional Boolean vectors with 1 at locations where a\n",
      "Queen is placed. We use another smaller NLM architecture as the latent model G φ .\n",
      "We train our model on 10–Queens puzzles and test on 11–Queens puzzles, both with 5 placed queens.\n",
      "This size-invariance in training and test is a key strength of NLM architecture, which we exploit\n",
      "in our experiments. To generate the train data, we start with all possible valid 10–Queens board\n",
      "conﬁgurations and randomly mask any 5 queens, and then check for all possible valid completions to\n",
      "3 Further details of software environments, hyperparameters and dataset generation are in the appendix.\n",
      "generate potentially multiple solutions for an input. Test data is also generated similarly. Training\n",
      "and testing on different board sizes ensures that no direct information leaks from test to train. Queries\n",
      "with multiple solutions have 2-6 solutions, so we choose Y x i = Y x i , ∀ x i .\n",
      "Futoshiki: This is a logic puzzle in which we are given a grid of size N × N , and the goal is to\n",
      "ﬁll the grid with digits from { 1 . . . N } such that no digit is repeated in a row or a column. k out of\n",
      "N 2 positions are already ﬁlled in the input query x and the remaining N 2 − k positions need to be\n",
      "ﬁlled. Further, inequality constraints are speciﬁed between some pairs of adjacent grid positions,\n",
      "which need to be honored in the solution. Our prediction network, and latent model use NLM, and\n",
      "the details (described in Appendix) are very similar to that of N–Queens.\n",
      "Similar to N–Queens, we do size-invariant training – we train our models on 5 × 5 puzzles with 14\n",
      "missing digits and test on 6 × 6 puzzles with 20 missing digits. Similar to N–Queens, we generate all\n",
      "possible valid grids and randomly mask out the requisite number of digits to generate train and test\n",
      "data. For both train and test queries we keep up to ﬁve inequality constraints of each type: > and < .\n",
      "Sudoku: We also experiment on Sudoku, which has been used as the task of choice for many recent\n",
      "neural reasoning works (Palm et al., 2018; Wang et al., 2019). We use Relational Recurrent Networks\n",
      "(RRN) (Palm et al., 2018) as the prediction network since it has recently shown state-of-the-art\n",
      "performance on the task. We use a 5 layer CNN as our latent model G φ . Existing Sudoku datasets\n",
      "(Royle, 2014; Park, 2018), do not expose the issues with solution multiplicity. In response, we\n",
      "generate our own dataset by starting with a collection of Sudoku puzzles with unique solutions that\n",
      "have 17 digits ﬁlled. We remove one of the digits, thus generating a puzzle, which is guaranteed to\n",
      "have solution multiplicity. We then randomly add 1 to 18 of the digits back from the solution of the\n",
      "original puzzle, while ensuring that the query continues to have more than 1 solution. This generates\n",
      "our set of multi-solution queries with a uniform distribution of ﬁlled digits from 17 to 34. We mix an\n",
      "equal number of unique solution queries (with same ﬁlled distribution). Because some x i s may have\n",
      "hundreds of solutions, we randomly sample 5 of them from Y x i , i.e., | Y x i | ≤ 5 in the train set. For\n",
      "each dataset, we generate a devset in a manner similar to the test set.\n",
      "B ASELINES AND E VALUATION M ETRIC\n",
      "Our comparison baselines include: (1) Naïve : backpropagating L (Θ) through each solution independently using Equation (1), (2) Unique : computing L (Θ) only over the subset of training examples\n",
      "that have a unique solution\n",
      "and (3) Random : backpropagating L (Θ) through one arbitrarily picked\n",
      "solution y i ∈ Y x i for every x i in the train data\n",
      "and keeping this choice ﬁxed throughout the training.\n",
      "We separately report performance on two mutually exclusive subsets of test data: OS : queries\n",
      "with a unique solution\n",
      "and MS : those with multiple solutions. For all methods, we tune various\n",
      "hyperparameters (and do early stopping) based on the devset performance. Additional parameters for\n",
      "the four multiplicity aware methods include the ratio of OS and MS examples in training. 4 I-E XPL R\n",
      "and S ELECT R also select the pre-training strategy as described in Section 3.5. For all tasks, we\n",
      "consider the output of a prediction network as correct only if it is a valid solution for the underlying\n",
      "CSP. No partial credit is given for guessing parts of the output correctly.\n",
      "4.3\n",
      "R ESULTS AND D ISCUSSION\n",
      "We report the accuracies across all tasks and models in Table 2. For each setting, we report the mean\n",
      "over three random runs (with different seeds), and also the accuracy on the best of these runs selected\n",
      "via the devset (in the parentheses). We ﬁrst observe that Naïve and Random perform signiﬁcantly\n",
      "worse than Unique in all the tasks, not only on MS , but on OS as well. This suggests that, 1 oML\n",
      "models that explicitly handle solution multiplicity, even if by simply discarding multiple solutions,\n",
      "are much better than those that do not recognize it at all.\n",
      "4 Futoshiki and N–Queens training datasets have signiﬁcant OS - MS imbalance (see Table 1), necessitating\n",
      "managing this ratio by undersampling OS . This is similar to standard approach in class imbalance problems.\n",
      "Predictably, all multiplicity aware methods vastly improve upon the performance of naïve baselines,\n",
      "with a dramatic 13-52 pt gains between Unique and S ELECT R on queries with multiple solutions.\n",
      "Comparing M IN L OSS and S ELECT R, we ﬁnd\n",
      "that our RL-based approach outperforms M IN -\n",
      "L OSS consistently, with p-values (computed\n",
      "using McNemar’s test for the best models selected based on validation set) of 1 . 00e − 16 ,\n",
      "0 . 03 , and 1 . 69e − 18 for NQueens, Futoshiki and\n",
      "Sudoku respectively (see Appendix for seed-wise comparisons of gains across tasks). On\n",
      "the other hand, informed exploration technique,\n",
      "I-E XPL R, though improves over M IN L OSS on\n",
      "two out of three tasks, it performs worse than\n",
      "S ELECT R in all the domains. This highlights\n",
      "the value of RL based exploration on top of the\n",
      "greedy target selection of M IN L OSS as well as\n",
      "over the simple exploration of I-E XPL R. We\n",
      "note that this is due to more exploratory power of S ELECT R over I-E XPL R. See Appendix for more\n",
      "discussion and experiments comparing the two exploration techniques.\n",
      "Recall that Sudoku training set has no more than 5 solutions for a query, irrespective of the actual\n",
      "number of solutions – i.e, for many x i , Y x i (cid:40) Y x i . Despite incomplete solution set, signiﬁcant\n",
      "improvement over baselines is obtained, indicating that our formulation handles solution multiplicity\n",
      "even with incomplete information. Furthermore, the large variation in the size of solution set ( |Y x | )\n",
      "in Sudoku allows us to assess its effect on the overall performance. We ﬁnd that all models get worse\n",
      "as |Y x | increases (ﬁg. 3), even though S ELECT R remains the most robust (see Appendix for details).\n",
      "C ONCLUSION AND F UTURE W ORK\n",
      "In this paper, we have deﬁned 1 oML: the task of learning one of many solutions for combinatorial\n",
      "problems in structured output spaces. We have identiﬁed solution multiplicity as an important aspect\n",
      "of the problem, which if not handled properly, may result in sub-optimal models. As a ﬁrst cut\n",
      "solution, we proposed a greedy approach: M IN L OSS formulation. We identiﬁed certain shortcomings\n",
      "with the greedy approach and proposed two exploration based formulations: I-E XPL R and an RL\n",
      "formulation, S ELECT R, which overcomes some of the issues in M IN L OSS by exploring the locally\n",
      "sub-optimal choices for better global optimization.\n",
      "Experiments on three different tasks using two different prediction networks demonstrate the effectiveness of our approach in training robust models under solution multiplicity 5 .\n",
      "It is interesting to note that for traditional CSP solvers, e.g. (Selman et al., 1993; Mahajan et al., 2004),\n",
      "a problem with many solutions will be considered an easy problem, whereas for neural models, such\n",
      "problems appear much harder (Figure 3). As a future work, it will be interesting to combine symbolic\n",
      "CSP solvers with S ELECT R to design a much stronger neuro-symbolic reasoning model.\n",
      "5 All the code and datasets are available at: https://sites.google.com/view/yatinnandwani/1oml\n",
      "A CKNOWLEDGEMENT\n",
      "We thank IIT Delhi HPC facility 6 for computational resources. We thank anonymous reviewers for\n",
      "their insightful comments and suggestions, in particular AnonReviewer4 for suggesting a simple yet\n",
      "effective informed exploration strategy (I-E XPL R). Mausam is supported by grants from Google,\n",
      "Bloomberg, 1MG and Jai Gupta chair fellowship by IIT Delhi. Parag Singla is supported by the\n",
      "DARPA Explainable Artiﬁcial Intelligence (XAI) Program with number N66001-17-2-4032. Both\n",
      "Mausam and Parag Singla are supported by the Visvesvaraya Young Faculty Fellowships by Govt. of\n",
      "India and IBM SUR awards. Any opinions, ﬁndings, conclusions or recommendations expressed in\n",
      "this paper are those of the authors and do not necessarily reﬂect the views or ofﬁcial policies, either\n",
      "expressed or implied, of the funding agencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# ===== 1. 读取 CSV 文件 =====\n",
    "file_path = r\"E:\\judita's project\\new data 2\\paper_id_intro_conclusion_combined.csv\"\n",
    "df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "\n",
    "# ===== 3. 随机抽取一个 paper_id =====\n",
    "random_row = df.sample(n=1).iloc[0]\n",
    "\n",
    "# ===== 4. 打印所有相关字段内容 =====\n",
    "print(f\"🆔 paper_id: {random_row['paper_id']}\\n\")\n",
    "print(f\"📄 Title:\\n{random_row['title']}\\n\")\n",
    "print(f\"📜 Abstract:\\n{random_row['abstract']}\\n\")\n",
    "print(f\"📘 Introduction:\\n{random_row['introduction']}\\n\")\n",
    "print(f\"📕 Conclusion:\\n{random_row['conclusion']}\\n\")\n",
    "print(f\"📎 title+abstract:\\n{random_row['title+abstract']}\\n\")\n",
    "print(f\"📎 title+abstract+introduction:\\n{random_row['title+abstract+introduction']}\\n\")\n",
    "print(f\"📎 title+abstract+introduction+conclusion:\\n{random_row['title+abstract+introduction+conclusion']}\\n\")\n",
    "print(f\"📎 title+abstract+conclusion:\\n{random_row['title+abstract+conclusion']}\\n\")\n",
    "print(f\"📎 title+introduction+conclusion:\\n{random_row['title+introduction+conclusion']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d932a69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merge complete, output file path: E:\\judita's project\\new data 2\\paper_id_intro_conclusion_combined_final.csv\n",
      "\n",
      "📊 Missing value statistics (after merge):\n",
      "page_count         0\n",
      "citation_count     0\n",
      "figure_count       0\n",
      "table_count        0\n",
      "reference_count    0\n",
      "publication        0\n",
      "year               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# === 1. 文件路径（请根据实际路径修改）===\n",
    "csv_file_path = r\"E:\\judita's project\\new data 2\\paper_id_intro_conclusion_combined.csv\"  # ✅ CSV 文件\n",
    "json_file_path = r\"E:\\judita's project\\全部数据\\judita_统一ICLR7.7更新后.json\"  # ✅ JSON 文件\n",
    "output_path = r\"E:\\judita's project\\new data 2\\paper_id_intro_conclusion_combined_final.csv\"  # ✅ 输出文件\n",
    "\n",
    "# === 2. 加载 CSV 文件 ===\n",
    "df_csv = pd.read_csv(csv_file_path)\n",
    "df_csv[\"paper_id\"] = df_csv[\"paper_id\"].astype(str).str.strip()\n",
    "\n",
    "# === 3. 加载 JSON 文件 ===\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# === 4. 将 JSON 数据转为 DataFrame，并重命名 id 为 paper_id ===\n",
    "df_json = pd.DataFrame(json_data)\n",
    "df_json = df_json.rename(columns={\"id\": \"paper_id\"})\n",
    "df_json[\"paper_id\"] = df_json[\"paper_id\"].astype(str).str.strip()\n",
    "\n",
    "# 只保留需要的字段（你也可以修改此列表）\n",
    "columns_needed = [\n",
    "    \"paper_id\", \"page_count\", \"citation_count\", \"figure_count\", \"table_count\", \"reference_count\", \"publication\", \"year\"\n",
    "]\n",
    "df_json = df_json[columns_needed]\n",
    "\n",
    "# === 5. 合并两个数据集（保留 CSV 中的原始顺序）===\n",
    "df_merged = df_csv.merge(df_json, on=\"paper_id\", how=\"left\")\n",
    "\n",
    "# === 6. 保存结果 ===\n",
    "df_merged.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ Merge complete, output file path:\", output_path)\n",
    "missing = df_merged[[\"page_count\", \"citation_count\", \"figure_count\", \"table_count\", \"reference_count\", \"publication\", \"year\"]].isna().sum()\n",
    "print(\"\\n📊 Missing value statistics (after merge):\")\n",
    "print(missing)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
